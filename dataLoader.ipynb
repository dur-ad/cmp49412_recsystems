{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd47ab0",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a393fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries load\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae754399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current folder directory set up\n",
    "DIR = os.path.join(os.getcwd(), 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157b5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_book_works.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_book_authors.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_book_series.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_books.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_book_genres_initial.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_children.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_comics_graphic.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_fantasy_paranormal.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_history_biography.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_mystery_thriller_crime.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_poetry.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_romance.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_books_young_adult.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_children.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_comics_graphic.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_fantasy_paranormal.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_history_biography.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_mystery_thriller_crime....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_poetry.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_romance.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_interactions_young_adult.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_children.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_comics_graphic.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_fantasy_paranormal.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_history_biography.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_mystery_thriller_crime.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_poetry.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_romance.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>byGenre</td>\n",
       "      <td>goodreads_reviews_young_adult.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>complete</td>\n",
       "      <td>book_id_map.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>complete</td>\n",
       "      <td>user_id_map.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_interactions.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_reviews_dedup.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_reviews_spoiler.json.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>complete</td>\n",
       "      <td>goodreads_reviews_spoiler_raw.json.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                               name\n",
       "0   complete                       goodreads_book_works.json.gz\n",
       "1   complete                     goodreads_book_authors.json.gz\n",
       "2   complete                      goodreads_book_series.json.gz\n",
       "3   complete                            goodreads_books.json.gz\n",
       "4   complete              goodreads_book_genres_initial.json.gz\n",
       "5    byGenre                   goodreads_books_children.json.gz\n",
       "6    byGenre             goodreads_books_comics_graphic.json.gz\n",
       "7    byGenre         goodreads_books_fantasy_paranormal.json.gz\n",
       "8    byGenre          goodreads_books_history_biography.json.gz\n",
       "9    byGenre     goodreads_books_mystery_thriller_crime.json.gz\n",
       "10   byGenre                     goodreads_books_poetry.json.gz\n",
       "11   byGenre                    goodreads_books_romance.json.gz\n",
       "12   byGenre                goodreads_books_young_adult.json.gz\n",
       "13   byGenre            goodreads_interactions_children.json.gz\n",
       "14   byGenre      goodreads_interactions_comics_graphic.json.gz\n",
       "15   byGenre  goodreads_interactions_fantasy_paranormal.json.gz\n",
       "16   byGenre   goodreads_interactions_history_biography.json.gz\n",
       "17   byGenre  goodreads_interactions_mystery_thriller_crime....\n",
       "18   byGenre              goodreads_interactions_poetry.json.gz\n",
       "19   byGenre             goodreads_interactions_romance.json.gz\n",
       "20   byGenre         goodreads_interactions_young_adult.json.gz\n",
       "21   byGenre                 goodreads_reviews_children.json.gz\n",
       "22   byGenre           goodreads_reviews_comics_graphic.json.gz\n",
       "23   byGenre       goodreads_reviews_fantasy_paranormal.json.gz\n",
       "24   byGenre        goodreads_reviews_history_biography.json.gz\n",
       "25   byGenre   goodreads_reviews_mystery_thriller_crime.json.gz\n",
       "26   byGenre                   goodreads_reviews_poetry.json.gz\n",
       "27   byGenre                  goodreads_reviews_romance.json.gz\n",
       "28   byGenre              goodreads_reviews_young_adult.json.gz\n",
       "29  complete                                    book_id_map.csv\n",
       "30  complete                                    user_id_map.csv\n",
       "31  complete                         goodreads_interactions.csv\n",
       "32  complete                    goodreads_reviews_dedup.json.gz\n",
       "33  complete                  goodreads_reviews_spoiler.json.gz\n",
       "34  complete              goodreads_reviews_spoiler_raw.json.gz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the expected files using dataset_names.csv\n",
    "file_path = os.path.join(DIR, 'dataset_names.csv')\n",
    "file_names = pd.read_csv(file_path)\n",
    "display(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4078ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found: goodreads_book_works.json.gz\n",
      "found: goodreads_book_authors.json.gz\n",
      "found: goodreads_book_series.json.gz\n",
      "found: goodreads_books.json.gz\n",
      "found: goodreads_book_genres_initial.json.gz\n",
      "found: goodreads_books_children.json.gz\n",
      "found: goodreads_books_comics_graphic.json.gz\n",
      "found: goodreads_books_fantasy_paranormal.json.gz\n",
      "found: goodreads_books_history_biography.json.gz\n",
      "found: goodreads_books_mystery_thriller_crime.json.gz\n",
      "found: goodreads_books_poetry.json.gz\n",
      "found: goodreads_books_romance.json.gz\n",
      "found: goodreads_books_young_adult.json.gz\n",
      "found: goodreads_interactions_children.json.gz\n",
      "found: goodreads_interactions_comics_graphic.json.gz\n",
      "found: goodreads_interactions_fantasy_paranormal.json.gz\n",
      "found: goodreads_interactions_history_biography.json.gz\n",
      "found: goodreads_interactions_mystery_thriller_crime.json.gz\n",
      "found: goodreads_interactions_poetry.json.gz\n",
      "found: goodreads_interactions_romance.json.gz\n",
      "found: goodreads_interactions_young_adult.json.gz\n",
      "found: goodreads_reviews_children.json.gz\n",
      "found: goodreads_reviews_comics_graphic.json.gz\n",
      "found: goodreads_reviews_fantasy_paranormal.json.gz\n",
      "found: goodreads_reviews_history_biography.json.gz\n",
      "found: goodreads_reviews_mystery_thriller_crime.json.gz\n",
      "found: goodreads_reviews_poetry.json.gz\n",
      "found: goodreads_reviews_romance.json.gz\n",
      "found: goodreads_reviews_young_adult.json.gz\n",
      "found: book_id_map.csv\n",
      "found: user_id_map.csv\n",
      "found: goodreads_interactions.csv\n",
      "found: goodreads_reviews_dedup.json.gz\n",
      "missing: goodreads_reviews_spoiler.json.gz\n",
      "missing: goodreads_reviews_spoiler_raw.json.gz\n"
     ]
    }
   ],
   "source": [
    "#check the available files in the folder (note that not all of them were needed)\n",
    "available_files = os.listdir(DIR)\n",
    "for name in file_names[\"name\"]:\n",
    "    if name in available_files:\n",
    "        print(f\"found: {name}\")\n",
    "    else:\n",
    "        print(f\"missing: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08128fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the data and open the compressed files (base inspiration source: the goodreads dataset github)\n",
    "\n",
    "def load_data(file_name, sample_size=100000, head=None):\n",
    "    \"\"\"\n",
    "    Load line-delimited JSON records from a compressed .json.gz file.\n",
    "    - If head is set => return the first N rows quickly.\n",
    "    - Else => use reservoir sampling to get a random sample of sample_size rows.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as fin:\n",
    "        if head is not None:\n",
    "            # just take the first 'head' rows\n",
    "            for idx, line in enumerate(fin):\n",
    "                if idx >= head:\n",
    "                    break\n",
    "                data.append(json.loads(line))\n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            # reservoir sampling\n",
    "            sample = []\n",
    "            for idx, line in enumerate(fin, 1):\n",
    "                record = json.loads(line)\n",
    "                if len(sample) < sample_size:\n",
    "                    sample.append(record)\n",
    "                else:\n",
    "                    j = random.randint(0, idx-1)\n",
    "                    if j < sample_size:\n",
    "                        sample[j] = record\n",
    "            return pd.DataFrame(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23df6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample book record\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>series</th>\n",
       "      <th>country_code</th>\n",
       "      <th>language_code</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>asin</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>kindle_asin</th>\n",
       "      <th>...</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>edition_information</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>book_id</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>title_without_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0312853122</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '3', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>1984</td>\n",
       "      <td>https://www.goodreads.com/book/show/5333265-w-...</td>\n",
       "      <td>https://images.gr-assets.com/books/1310220028m...</td>\n",
       "      <td>5333265</td>\n",
       "      <td>3</td>\n",
       "      <td>5400751</td>\n",
       "      <td>W.C. Fields: A Life on Film</td>\n",
       "      <td>W.C. Fields: A Life on Film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn text_reviews_count series country_code language_code  \\\n",
       "0  0312853122                  1     []           US                 \n",
       "\n",
       "                                     popular_shelves asin is_ebook  \\\n",
       "0  [{'count': '3', 'name': 'to-read'}, {'count': ...         false   \n",
       "\n",
       "  average_rating kindle_asin  ... publication_month edition_information  \\\n",
       "0           4.00              ...                 9                       \n",
       "\n",
       "  publication_year                                                url  \\\n",
       "0             1984  https://www.goodreads.com/book/show/5333265-w-...   \n",
       "\n",
       "                                           image_url  book_id ratings_count  \\\n",
       "0  https://images.gr-assets.com/books/1310220028m...  5333265             3   \n",
       "\n",
       "   work_id                        title         title_without_series  \n",
       "0  5400751  W.C. Fields: A Life on Film  W.C. Fields: A Life on Film  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample record from books dataset (only for display and format familiarization)\n",
    "books_sample = load_data(os.path.join(DIR, 'goodreads_books.json.gz'), head=1)\n",
    "print('sample book record')\n",
    "display(books_sample.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd263ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books loaded (sampled 100k)\n"
     ]
    }
   ],
   "source": [
    "#main dataset (sample 100,000 books for efficiency)\n",
    "books = load_data(os.path.join(DIR, 'goodreads_books.json.gz'), sample_size=100000)\n",
    "print(\"books loaded (sampled 100k)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d82dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book works loaded\n",
      "authors loaded\n",
      "series loaded\n",
      "reviews loaded\n",
      "fuzzy genres loaded\n"
     ]
    }
   ],
   "source": [
    "#other metadata datasets (sample random 100k for efficiency and fairness => unique )\n",
    "bookworks = load_data(os.path.join(DIR, 'goodreads_book_works.json.gz'), sample_size=100000)\n",
    "print(\"book works loaded\")\n",
    "\n",
    "authors = load_data(os.path.join(DIR, 'goodreads_book_authors.json.gz'), sample_size=100000)\n",
    "print(\"authors loaded\")\n",
    "\n",
    "series = load_data(os.path.join(DIR, 'goodreads_book_series.json.gz'), sample_size=100000)\n",
    "print(\"series loaded\")\n",
    "\n",
    "reviews = load_data(os.path.join(DIR, 'goodreads_reviews_dedup.json.gz'), sample_size=100000)\n",
    "print(\"reviews loaded\")\n",
    "\n",
    "fuzzy_genres = load_data(os.path.join(DIR, 'goodreads_book_genres_initial.json.gz'), sample_size=100000)\n",
    "print(\"fuzzy genres loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca2f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv read (these are smaller so load fully)\n",
    "user_interaction = pd.read_csv(os.path.join(DIR, 'goodreads_interactions.csv'))\n",
    "book_id_map = pd.read_csv(os.path.join(DIR, 'book_id_map.csv'))\n",
    "user_id_map = pd.read_csv(os.path.join(DIR, 'user_id_map.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2aab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id_csv', 'user_id'], dtype='object')\n",
      "Index(['book_id_csv', 'book_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(user_id_map.columns)\n",
    "print(book_id_map.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e6d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'book_id', 'is_read', 'rating', 'is_reviewed'], dtype='object')\n",
      "Index(['book_id_csv', 'book_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(user_interaction.columns)\n",
    "print(book_id_map.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6555e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User interactions mapped with book and user ids\n"
     ]
    }
   ],
   "source": [
    "# merge interactions with book_id_map\n",
    "user_interaction = user_interaction.merge(\n",
    "    book_id_map, left_on='book_id', right_on='book_id_csv', how='left'\n",
    ")\n",
    "\n",
    "# merge interactions with user_id_map\n",
    "user_interaction = user_interaction.merge(\n",
    "    user_id_map, left_on='user_id', right_on='user_id_csv', how='left'\n",
    ")\n",
    "\n",
    "# drop the redundant csv columns\n",
    "user_interaction = user_interaction.drop(columns=['book_id_csv', 'user_id_csv'])\n",
    "\n",
    "print(\"User interactions mapped with book and user ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "748e9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user interactions sampled\n"
     ]
    }
   ],
   "source": [
    "#sample 100,000 interactions for efficiency\n",
    "user_interaction_sample = user_interaction.sample(n=100000, random_state=42)\n",
    "print(\"user interactions sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b12af44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children loaded\n",
      "comics loaded\n",
      "fantasy loaded\n",
      "mystery loaded\n",
      "poetry loaded\n",
      "romance loaded\n",
      "young adult loaded\n",
      "history loaded\n"
     ]
    }
   ],
   "source": [
    "#genres => load datasets that are genre specific (sample 100,000 each)\n",
    "books_children = load_data(os.path.join(DIR, 'goodreads_books_children.json.gz'), sample_size=100000)\n",
    "interactions_children = load_data(os.path.join(DIR, 'goodreads_interactions_children.json.gz'), sample_size=100000)\n",
    "reviews_children = load_data(os.path.join(DIR, 'goodreads_reviews_children.json.gz'), sample_size=100000)\n",
    "print(\"children loaded\")\n",
    "\n",
    "books_comics = load_data(os.path.join(DIR, 'goodreads_books_comics_graphic.json.gz'), sample_size=100000)\n",
    "interactions_comics = load_data(os.path.join(DIR, 'goodreads_interactions_comics_graphic.json.gz'), sample_size=100000)\n",
    "reviews_comics = load_data(os.path.join(DIR, 'goodreads_reviews_comics_graphic.json.gz'), sample_size=100000)\n",
    "print(\"comics loaded\")\n",
    "\n",
    "books_fantasy = load_data(os.path.join(DIR, 'goodreads_books_fantasy_paranormal.json.gz'), sample_size=100000)\n",
    "interactions_fantasy = load_data(os.path.join(DIR, 'goodreads_interactions_fantasy_paranormal.json.gz'), sample_size=100000)\n",
    "reviews_fantasy = load_data(os.path.join(DIR, 'goodreads_reviews_fantasy_paranormal.json.gz'), sample_size=100000)\n",
    "print(\"fantasy loaded\")\n",
    "\n",
    "books_mystery = load_data(os.path.join(DIR, 'goodreads_books_mystery_thriller_crime.json.gz'), sample_size=100000)\n",
    "interactions_mystery = load_data(os.path.join(DIR, 'goodreads_interactions_mystery_thriller_crime.json.gz'), sample_size=100000)\n",
    "reviews_mystery = load_data(os.path.join(DIR, 'goodreads_reviews_mystery_thriller_crime.json.gz'), sample_size=100000)\n",
    "print(\"mystery loaded\")\n",
    "\n",
    "books_poetry = load_data(os.path.join(DIR, 'goodreads_books_poetry.json.gz'), sample_size=100000)\n",
    "interactions_poetry = load_data(os.path.join(DIR, 'goodreads_interactions_poetry.json.gz'), sample_size=100000)\n",
    "reviews_poetry = load_data(os.path.join(DIR, 'goodreads_reviews_poetry.json.gz'), sample_size=100000)\n",
    "print(\"poetry loaded\")\n",
    "\n",
    "books_romance = load_data(os.path.join(DIR, 'goodreads_books_romance.json.gz'), sample_size=100000)\n",
    "interactions_romance = load_data(os.path.join(DIR, 'goodreads_interactions_romance.json.gz'), sample_size=100000)\n",
    "reviews_romance = load_data(os.path.join(DIR, 'goodreads_reviews_romance.json.gz'), sample_size=100000)\n",
    "print(\"romance loaded\")\n",
    "\n",
    "books_young_adult = load_data(os.path.join(DIR, 'goodreads_books_young_adult.json.gz'), sample_size=100000)\n",
    "interactions_young_adult = load_data(os.path.join(DIR, 'goodreads_interactions_young_adult.json.gz'), sample_size=100000)\n",
    "reviews_young_adult = load_data(os.path.join(DIR, 'goodreads_reviews_young_adult.json.gz'), sample_size=100000)\n",
    "print(\"young adult loaded\")\n",
    "\n",
    "book_history = load_data(os.path.join(DIR, 'goodreads_books_history_biography.json.gz'), sample_size=100000)\n",
    "interactions_history = load_data(os.path.join(DIR, 'goodreads_interactions_history_biography.json.gz'), sample_size=100000)\n",
    "reviews_history = load_data(os.path.join(DIR, 'goodreads_reviews_history_biography.json.gz'), sample_size=100000)\n",
    "print(\"history loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de227c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put loaded datasets into a dictionary\n",
    "datasets = {\n",
    "    \"books\": books,\n",
    "    \"bookworks\": bookworks,\n",
    "    \"authors\": authors,\n",
    "    \"series\": series,\n",
    "    \"reviews\": reviews,\n",
    "    \"fuzzy_genres\": fuzzy_genres,\n",
    "\n",
    "    #genre-specific\n",
    "    \"books_children\": books_children,\n",
    "    \"interactions_children\": interactions_children,\n",
    "    \"reviews_children\": reviews_children,\n",
    "\n",
    "    \"books_comics\": books_comics,\n",
    "    \"interactions_comics\": interactions_comics,\n",
    "    \"reviews_comics\": reviews_comics,\n",
    "\n",
    "    \"books_fantasy\": books_fantasy,\n",
    "    \"interactions_fantasy\": interactions_fantasy,\n",
    "    \"reviews_fantasy\": reviews_fantasy,\n",
    "\n",
    "    \"books_mystery\": books_mystery,\n",
    "    \"interactions_mystery\": interactions_mystery,\n",
    "    \"reviews_mystery\": reviews_mystery,\n",
    "\n",
    "    \"books_poetry\": books_poetry,\n",
    "    \"interactions_poetry\": interactions_poetry,\n",
    "    \"reviews_poetry\": reviews_poetry,\n",
    "\n",
    "    \"books_romance\": books_romance,\n",
    "    \"interactions_romance\": interactions_romance,\n",
    "    \"reviews_romance\": reviews_romance,\n",
    "\n",
    "    \"books_young_adult\": books_young_adult,\n",
    "    \"interactions_young_adult\": interactions_young_adult,\n",
    "    \"reviews_young_adult\": reviews_young_adult,\n",
    "\n",
    "    \"books_history\": book_history,\n",
    "    \"interactions_history\": interactions_history,\n",
    "    \"reviews_history\": reviews_history,\n",
    "\n",
    "    #csv-based\n",
    "    \"user_interaction\": user_interaction_sample,\n",
    "    \"book_id_map\": book_id_map,\n",
    "    \"user_id_map\": user_id_map,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd6017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved books.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved bookworks.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved authors.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved series.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved fuzzy_genres.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_children.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_children.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_children.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_comics.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_comics.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_comics.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_fantasy.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_fantasy.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_fantasy.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_mystery.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_mystery.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_mystery.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_poetry.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_poetry.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_poetry.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_romance.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_romance.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_romance.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_young_adult.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_young_adult.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_young_adult.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved books_history.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved interactions_history.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved reviews_history.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved user_interaction.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved book_id_map.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "saved user_id_map.pkl to c:\\Users\\nourh\\Documents\\GoodReadsRecommendationSystem\\Data\\Pickle\n",
      "all datasets saved to Pickle folder successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# base directory\n",
    "PICKLE_DIR = os.path.join(DIR, \"Pickle\")\n",
    "os.makedirs(PICKLE_DIR, exist_ok=True)  # create folder if it doesn't exist\n",
    "\n",
    "# save with pickle into Pickle folder\n",
    "for name, df in datasets.items():\n",
    "    file_path = os.path.join(PICKLE_DIR, f\"{name}.pkl\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(df, f)\n",
    "    print(f\"saved {name}.pkl to {PICKLE_DIR}\")\n",
    "\n",
    "print(\"all datasets saved to Pickle folder successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde284f",
   "metadata": {},
   "source": [
    "## datasets that need full load => might be helpful going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87836481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to fully load  JSON from .json.gz \n",
    "def load_full_data(file_name, head=None):\n",
    "    \"\"\"\n",
    "    Fully load line-delimited JSON records from a compressed .json.gz file.\n",
    "    - If head is set: return only the first N rows.\n",
    "    - Else: load the entire dataset.\n",
    "    Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with gzip.open(file_name, 'rt', encoding='utf-8') as fin:\n",
    "        for idx, line in enumerate(fin):\n",
    "            record = json.loads(line)\n",
    "            data.append(record)\n",
    "            if head is not None and idx + 1 >= head:\n",
    "                break\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7f2a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "FULL_PICKLE_DIR = os.path.join(os.getcwd(), \"Data\", \"FullyLoaded\")\n",
    "\n",
    "# create new pickle folder if it doesn't exist\n",
    "os.makedirs(FULL_PICKLE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c70cb36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors loaded: (829529, 5)\n",
      "series loaded: (400390, 7)\n",
      "bookworks loaded: (1521962, 16)\n",
      "fuzzy genres loaded: (2360655, 2)\n"
     ]
    }
   ],
   "source": [
    "# full load \n",
    "authors_full = load_full_data(os.path.join(DIR, \"goodreads_book_authors.json.gz\"))\n",
    "print(\"authors loaded:\", authors_full.shape)\n",
    "\n",
    "series_full = load_full_data(os.path.join(DIR, \"goodreads_book_series.json.gz\"))\n",
    "print(\"series loaded:\", series_full.shape)\n",
    "\n",
    "bookworks_full = load_full_data(os.path.join(DIR, \"goodreads_book_works.json.gz\"))\n",
    "print(\"bookworks loaded:\", bookworks_full.shape)\n",
    "\n",
    "fuzzy_genres_full = load_full_data(os.path.join(DIR, \"goodreads_book_genres_initial.json.gz\"))\n",
    "print(\"fuzzy genres loaded:\", fuzzy_genres_full.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1418cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a  dictionary\n",
    "datasets_full = {\n",
    "    \"user_interaction\": user_interaction,\n",
    "    \"authors_full\": authors_full,\n",
    "    \"series_full\": series_full,\n",
    "    \"bookworks_full\": bookworks_full,\n",
    "    \"fuzzy_genres_full\": fuzzy_genres_full\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53557511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " user_interaction saved to FullyLoaded.\n",
      " authors_full saved to FullyLoaded.\n",
      " series_full saved to FullyLoaded.\n",
      " bookworks_full saved to FullyLoaded.\n",
      " fuzzy_genres_full saved to FullyLoaded.\n"
     ]
    }
   ],
   "source": [
    "# save to FullyLoaded pickle folder\n",
    "for name, df in datasets_full.items():\n",
    "    df.to_pickle(os.path.join(FULL_PICKLE_DIR, f\"{name}.pkl\"))\n",
    "    print(f\" {name} saved to FullyLoaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b06d3",
   "metadata": {},
   "source": [
    "### Adjusting time columns in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cf6178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [\"date_added\", \"date_updated\", \"read_at\", \"started_at\"] #define columns you want to make sure are the correct type\n",
    "\n",
    "\n",
    "for col in date_cols:\n",
    "    if col in reviews.columns:  # safety check\n",
    "        reviews[col] = pd.to_datetime(reviews[col], errors=\"coerce\")#convert to NaN instead of error \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fa22490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_added      datetime64[ns, tzoffset(None, -25200)]\n",
      "date_updated    datetime64[ns, tzoffset(None, -25200)]\n",
      "read_at         datetime64[ns, tzoffset(None, -25200)]\n",
      "started_at      datetime64[ns, tzoffset(None, -25200)]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(reviews[date_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3eb09bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_added      datetime64[ns, tzoffset(None, -25200)]\n",
      "date_updated    datetime64[ns, tzoffset(None, -25200)]\n",
      "read_at         datetime64[ns, tzoffset(None, -25200)]\n",
      "started_at      datetime64[ns, tzoffset(None, -25200)]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verify dtypes conversion\n",
    "print(reviews[date_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b08e118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-03 06:11:47-07:00</td>\n",
       "      <td>2017-08-09 12:57:12-07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-16 01:24:18-07:00</td>\n",
       "      <td>2012-04-16 01:26:57-07:00</td>\n",
       "      <td>1998-06-30 00:00:00-07:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-17 15:57:26-07:00</td>\n",
       "      <td>2016-09-02 17:54:46-07:00</td>\n",
       "      <td>2016-09-02 00:00:00-07:00</td>\n",
       "      <td>2016-08-17 00:00:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date_added              date_updated  \\\n",
       "0 2017-07-03 06:11:47-07:00 2017-08-09 12:57:12-07:00   \n",
       "1 2012-04-16 01:24:18-07:00 2012-04-16 01:26:57-07:00   \n",
       "2 2016-08-17 15:57:26-07:00 2016-09-02 17:54:46-07:00   \n",
       "3                       NaT                       NaT   \n",
       "4                       NaT                       NaT   \n",
       "\n",
       "                    read_at                started_at  \n",
       "0                       NaT                       NaT  \n",
       "1 1998-06-30 00:00:00-07:00                       NaT  \n",
       "2 2016-09-02 00:00:00-07:00 2016-08-17 00:00:00-07:00  \n",
       "3                       NaT                       NaT  \n",
       "4                       NaT                       NaT  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows \n",
    "reviews[[\"date_added\", \"date_updated\", \"read_at\", \"started_at\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b9fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2011-08-20 13:50:26-07:00</td>\n",
       "      <td>2011-08-27 10:07:49-07:00</td>\n",
       "      <td>2011-08-01 00:00:00-07:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2014-11-01 00:00:00-07:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-08-01 00:00:00-07:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-03-29 09:22:14-07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2017-10-24 13:56:07-07:00</td>\n",
       "      <td>2017-10-24 14:12:32-07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date_added              date_updated  \\\n",
       "99995 2011-08-20 13:50:26-07:00 2011-08-27 10:07:49-07:00   \n",
       "99996                       NaT                       NaT   \n",
       "99997                       NaT                       NaT   \n",
       "99998                       NaT 2013-03-29 09:22:14-07:00   \n",
       "99999 2017-10-24 13:56:07-07:00 2017-10-24 14:12:32-07:00   \n",
       "\n",
       "                        read_at started_at  \n",
       "99995 2011-08-01 00:00:00-07:00        NaT  \n",
       "99996 2014-11-01 00:00:00-07:00        NaT  \n",
       "99997 2016-08-01 00:00:00-07:00        NaT  \n",
       "99998                       NaT        NaT  \n",
       "99999                       NaT        NaT  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[[\"date_added\", \"date_updated\", \"read_at\", \"started_at\"]].tail() #last five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a586bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per date column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date_added      34560\n",
       "date_updated    33377\n",
       "read_at         46457\n",
       "started_at      61952\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many missing\n",
    "print(\"Missing values per date column:\")\n",
    "reviews[[\"date_added\", \"date_updated\", \"read_at\", \"started_at\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fcff0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started_at Cleaned Data: (38048, 11)\n",
      "Date_added Cleaned Data: (65440, 11)\n",
      "Read_at Cleaned Data: (53543, 11)\n"
     ]
    }
   ],
   "source": [
    "# cleaned \"currently reading\" => trendy books users are reading recently\n",
    "reviews_started = reviews.dropna(subset=[\"started_at\"]).copy()\n",
    "print(\"Started_at Cleaned Data:\", reviews_started.shape)\n",
    "\n",
    "# cleaned \"buzzing books\" => trendy books users are reviewing recently \n",
    "reviews_added = reviews.dropna(subset=[\"date_added\"]).copy()\n",
    "print(\"Date_added Cleaned Data:\", reviews_added.shape)\n",
    "\n",
    "# cleaned for \"page turners\" => books people are finishing and not dropping recently\n",
    "reviews_read = reviews.dropna(subset=[\"read_at\"]).copy()\n",
    "print(\"Read_at Cleaned Data:\", reviews_read.shape)\n",
    "\n",
    "#done this way to avoid having really small data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86044826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reviews_started: (38048, 11)\n",
      "Saved reviews_added: (65440, 11)\n",
      "Saved reviews_read: (53543, 11)\n"
     ]
    }
   ],
   "source": [
    "# save cleaned datasets\n",
    "reviews_started_path = os.path.join(FULL_PICKLE_DIR, \"reviews_started.pkl\")\n",
    "reviews_added_path   = os.path.join(FULL_PICKLE_DIR, \"reviews_added.pkl\")\n",
    "reviews_read_path    = os.path.join(FULL_PICKLE_DIR, \"reviews_read.pkl\")\n",
    "\n",
    "reviews_started.to_pickle(reviews_started_path)\n",
    "reviews_added.to_pickle(reviews_added_path)\n",
    "reviews_read.to_pickle(reviews_read_path)\n",
    "\n",
    "print(\"Saved reviews_started:\", reviews_started.shape)\n",
    "print(\"Saved reviews_added:\", reviews_added.shape)\n",
    "print(\"Saved reviews_read:\", reviews_read.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
