{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d562207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f014712",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('goodreads_interactions.csv')\n",
    "\n",
    "#CSV columns:\n",
    "#user_id | book_id | is_read | rating | is_reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bdfe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  is_read  rating  is_reviewed\n",
       "0        0      948      1.0     5.0          0.0\n",
       "1        0      947      1.0     5.0          1.0\n",
       "2        0      946      1.0     5.0          0.0\n",
       "3        0      945      1.0     5.0          0.0\n",
       "4        0      944      1.0     5.0          0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87941e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics:\n",
      "  Min interactions: 1\n",
      "  Max interactions: 129,935\n",
      "  Mean interactions: 57.69\n",
      "  Median interactions: 6.0\n",
      "  Std deviation: 614.02\n"
     ]
    }
   ],
   "source": [
    "# Count how many times each book was interacted with\n",
    "book_interactions = original_data.groupby('book_id').size().reset_index(name='n_interactions')\n",
    "\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"  Min interactions: {book_interactions['n_interactions'].min()}\")\n",
    "print(f\"  Max interactions: {book_interactions['n_interactions'].max():,}\")\n",
    "print(f\"  Mean interactions: {book_interactions['n_interactions'].mean():.2f}\")\n",
    "print(f\"  Median interactions: {book_interactions['n_interactions'].median():.1f}\")\n",
    "print(f\"  Std deviation: {book_interactions['n_interactions'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bb9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentiles:\n",
      "  10th percentile: 1 interactions\n",
      "  25th percentile: 2 interactions\n",
      "  50th percentile: 6 interactions\n",
      "  75th percentile: 22 interactions\n",
      "  90th percentile: 76 interactions\n",
      "  95th percentile: 162 interactions\n",
      "  99th percentile: 780 interactions\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPercentiles:\")\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    val = book_interactions['n_interactions'].quantile(p/100)\n",
    "    print(f\"  {p}th percentile: {val:.0f} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0a3ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 123,731,803 interactions\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original: {len(original_data):,} interactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9956e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 254,205\n",
      "Books: 2,144,808\n"
     ]
    }
   ],
   "source": [
    "user_counts = original_data['user_id'].value_counts()\n",
    "book_counts = original_data['book_id'].value_counts()\n",
    "print(f\"Users: {len(user_counts):,}\")\n",
    "print(f\"Books: {len(book_counts):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3dafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid users (>=10 interactions): 254,196\n",
      "Valid books (>=50 interactions): 306,020\n"
     ]
    }
   ],
   "source": [
    "valid_users = set(user_counts[user_counts >= 10].index)\n",
    "valid_books = set(book_counts[book_counts >= 50].index)\n",
    "\n",
    "print(f\"Valid users (>=10 interactions): {len(valid_users):,}\")\n",
    "print(f\"Valid books (>=50 interactions): {len(valid_books):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1870e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: 106,826,044 interactions\n",
      "Books: 306,020\n",
      "Users: 254,178\n"
     ]
    }
   ],
   "source": [
    "mask = original_data['user_id'].isin(valid_users) & original_data['book_id'].isin(valid_books)\n",
    "data = original_data[mask].copy()\n",
    "print(f\"Filtered: {len(data):,} interactions\")\n",
    "print(f\"Books: {data['book_id'].nunique():,}\")\n",
    "print(f\"Users: {data['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26eea0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: 106,826,044 interactions\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current size: {len(data):,} interactions\")\n",
    "# sampling it down more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1871d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling to 1,000,000 interactions\n"
     ]
    }
   ],
   "source": [
    "# Sample to 1 million interactions\n",
    "target_size = 1_000_000\n",
    "\n",
    "if len(data) > target_size:\n",
    "    print(f\"\\nSampling to {target_size:,} interactions\")\n",
    "    data = data.sample(n=target_size, random_state=42)\n",
    "    \n",
    "    # Re-filter to ensure quality after sampling\n",
    "    \n",
    "    # Keep books with at least 20 interactions in sampled data\n",
    "    book_counts = data['book_id'].value_counts()\n",
    "    valid_books = book_counts[book_counts >= 20].index\n",
    "    data = data[data['book_id'].isin(valid_books)].copy()\n",
    "    \n",
    "    # Keep users with at least 5 interactions in sampled data\n",
    "    user_counts = data['user_id'].value_counts()\n",
    "    valid_users = user_counts[user_counts >= 5].index\n",
    "    data = data[data['user_id'].isin(valid_users)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb94520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SAMPLED DATASET:\n",
      "Interactions: 144,343\n",
      "Books: 7,208\n",
      "Users: 20,780\n",
      "Sparsity: 99.90%\n",
      "Avg interactions/book: 20.0\n",
      "Avg interactions/user: 6.9\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL SAMPLED DATASET:\")\n",
    "print(f\"Interactions: {len(data):,}\")\n",
    "print(f\"Books: {data['book_id'].nunique():,}\")\n",
    "print(f\"Users: {data['user_id'].nunique():,}\")\n",
    "print(f\"Sparsity: {100 * (1 - len(data) / (data['user_id'].nunique() * data['book_id'].nunique())):.2f}%\")\n",
    "print(f\"Avg interactions/book: {len(data) / data['book_id'].nunique():.1f}\")\n",
    "print(f\"Avg interactions/user: {len(data) / data['user_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df6a1e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving sampled dataset...\n",
      "Saved to: D:\\GoodreadsData_NEW\\sampled_1M_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving sampled dataset...\")\n",
    "folder = r\"D:\\GoodreadsData_NEW\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "data.to_csv(os.path.join(folder, 'sampled_1M_data.csv'), index=False)\n",
    "print(\"Saved to: D:\\\\GoodreadsData_NEW\\\\sampled_1M_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea23f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 20,780\n",
      "Books: 7,208\n"
     ]
    }
   ],
   "source": [
    "# Create index mappings\n",
    "users = sorted(data['user_id'].unique())\n",
    "books = sorted(data['book_id'].unique())\n",
    "\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "book_to_idx = {book: idx for idx, book in enumerate(books)}\n",
    "idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "idx_to_book = {idx: book for book, idx in book_to_idx.items()}\n",
    "\n",
    "print(f\"Users: {len(users):,}\")\n",
    "print(f\"Books: {len(books):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14ba2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (20780, 7208)\n",
      "Non-zero entries: 144,343\n",
      "Memory: ~0.00 GB\n",
      "Sparse matrix created!\n"
     ]
    }
   ],
   "source": [
    "row_indices = [user_to_idx[uid] for uid in data['user_id']]\n",
    "col_indices = [book_to_idx[bid] for bid in data['book_id']]\n",
    "ratings = data['rating'].values\n",
    "\n",
    "rating_matrix = csr_matrix(\n",
    "    (ratings, (row_indices, col_indices)),\n",
    "    shape=(len(users), len(books)),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "print(f\"Matrix shape: {rating_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {rating_matrix.nnz:,}\")\n",
    "print(f\"Memory: ~{rating_matrix.data.nbytes / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"Sparse matrix created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a97c1d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean user rating: 2.109\n",
      "Ratings centered!\n",
      "Non-zero entries after centering: 126,435\n"
     ]
    }
   ],
   "source": [
    "# Center Ratings\n",
    "\n",
    "# Compute user means\n",
    "user_rating_counts = np.diff(rating_matrix.indptr)\n",
    "user_rating_sums = np.array(rating_matrix.sum(axis=1)).flatten()\n",
    "\n",
    "# Avoid division by zero\n",
    "user_means = np.divide(\n",
    "    user_rating_sums, \n",
    "    user_rating_counts, \n",
    "    out=np.zeros_like(user_rating_sums), \n",
    "    where=user_rating_counts > 0\n",
    ")\n",
    "\n",
    "print(f\"Mean user rating: {user_means[user_means > 0].mean():.3f}\")\n",
    "\n",
    "# Center ratings (subtract user means)\n",
    "rating_matrix_centered = rating_matrix.copy().astype(np.float32)\n",
    "\n",
    "for user_idx in range(rating_matrix_centered.shape[0]):\n",
    "    start = rating_matrix_centered.indptr[user_idx]\n",
    "    end = rating_matrix_centered.indptr[user_idx + 1]\n",
    "    \n",
    "    if end > start and user_means[user_idx] > 0:\n",
    "        rating_matrix_centered.data[start:end] -= user_means[user_idx]\n",
    "\n",
    "# Clean any NaN values\n",
    "nan_count = np.isnan(rating_matrix_centered.data).sum()\n",
    "if nan_count > 0:\n",
    "    print(f\"Cleaning {nan_count} NaN values...\")\n",
    "    rating_matrix_centered.data = np.nan_to_num(rating_matrix_centered.data, nan=0.0)\n",
    "\n",
    "rating_matrix_centered.eliminate_zeros()\n",
    "\n",
    "print(f\"Ratings centered!\")\n",
    "print(f\"Non-zero entries after centering: {rating_matrix_centered.nnz:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "233b42db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution:\n",
      "rating\n",
      "0.0    78557\n",
      "1.0     1336\n",
      "2.0     3837\n",
      "3.0    14723\n",
      "4.0    24423\n",
      "5.0    21467\n",
      "Name: count, dtype: int64\n",
      "Zero ratings: 78557\n",
      "Non-zero ratings: 65786\n"
     ]
    }
   ],
   "source": [
    "# Check rating distribution\n",
    "print(\"Rating distribution:\")\n",
    "print(data['rating'].value_counts().sort_index())\n",
    "print(f\"Zero ratings: {(data['rating'] == 0).sum()}\")\n",
    "print(f\"Non-zero ratings: {(data['rating'] > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e5bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity computed in 0:00:00.053827\n",
      "Shape: (7208, 7208)\n",
      "Non-zero similarities: 880,324\n",
      "Memory: ~0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Compute Item-Item Similarity\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Compute adjusted cosine similarity\n",
    "item_similarity_sparse = cosine_similarity(\n",
    "    rating_matrix_centered.T, \n",
    "    dense_output=False\n",
    ")\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "print(f\"Similarity computed in {elapsed}\")\n",
    "print(f\"Shape: {item_similarity_sparse.shape}\")\n",
    "print(f\"Non-zero similarities: {item_similarity_sparse.nnz:,}\")\n",
    "print(f\"Memory: ~{item_similarity_sparse.data.nbytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846cabc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Computing co-occurrence...\n",
      "  Applying filter (min_common=5)...\n",
      "Filtered!\n",
      "Non-zero similarities: 7,232\n"
     ]
    }
   ],
   "source": [
    "# Filter by Minimum Common Users\n",
    "\n",
    "# Compute co-occurrence matrix\n",
    "print(\"  Computing co-occurrence...\")\n",
    "rating_binary = rating_matrix.copy()\n",
    "rating_binary.data = np.ones_like(rating_binary.data)\n",
    "cooccurrence = (rating_binary.T @ rating_binary).toarray()\n",
    "\n",
    "# Convert to dense for filtering\n",
    "item_similarity = item_similarity_sparse.toarray()\n",
    "\n",
    "# Apply minimum common users filter\n",
    "min_common = 5\n",
    "print(f\"  Applying filter (min_common={min_common})...\")\n",
    "item_similarity[cooccurrence < min_common] = 0\n",
    "np.fill_diagonal(item_similarity, 1.0)\n",
    "\n",
    "# Convert back to sparse\n",
    "item_similarity_sparse = csr_matrix(item_similarity)\n",
    "del item_similarity  # Free memory\n",
    "\n",
    "print(f\"Filtered!\")\n",
    "print(f\"Non-zero similarities: {item_similarity_sparse.nnz:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdb6d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean book rating: 1.702\n",
      "Book means computed!\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Compute Book Means\n",
    "\n",
    "book_rating_counts = np.diff(rating_matrix.tocsc().indptr)\n",
    "book_rating_sums = np.array(rating_matrix.sum(axis=0)).flatten()\n",
    "book_means = np.divide(\n",
    "    book_rating_sums, \n",
    "    book_rating_counts,\n",
    "    out=np.zeros_like(book_rating_sums),\n",
    "    where=book_rating_counts > 0\n",
    ")\n",
    "\n",
    "print(f\"Mean book rating: {book_means[book_means > 0].mean():.3f}\")\n",
    "print(\"Book means computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f090929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: D:\\GoodreadsData_NEW\\sparse_itemcf_model.pkl\n",
      "Model saved! Size: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Save the Model\n",
    "\n",
    "folder = r\"D:\\GoodreadsData_NEW\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "save_data = {\n",
    "    'rating_matrix': rating_matrix,\n",
    "    'item_similarity': item_similarity_sparse,\n",
    "    'user_means': user_means,\n",
    "    'book_means': book_means,\n",
    "    'user_to_idx': user_to_idx,\n",
    "    'book_to_idx': book_to_idx,\n",
    "    'idx_to_user': idx_to_user,\n",
    "    'idx_to_book': idx_to_book,\n",
    "    'min_common': min_common\n",
    "}\n",
    "\n",
    "model_file = os.path.join(folder, 'sparse_itemcf_model.pkl')\n",
    "print(f\"Saving to: {model_file}\")\n",
    "\n",
    "with open(model_file, 'wb') as f:\n",
    "    pickle.dump(save_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "file_size = os.path.getsize(model_file) / (1024**2)\n",
    "print(f\"Model saved! Size: {file_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb6d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test User: 5\n",
      "\n",
      "User has rated 2 books\n",
      "Sample ratings:\n",
      "  Book 6955: 4.0 stars\n",
      "  Book 7057: 5.0 stars\n",
      "\n",
      "Prediction test:\n",
      "  Book 6955\n",
      "  Actual rating: 4.0\n",
      "  Predicted rating: 4.00\n",
      "\n",
      "Top 10 Recommendations for User 5:\n",
      "   1. Book  23153 - Predicted: 5.00 stars\n",
      "   2. Book  23368 - Predicted: 5.00 stars\n",
      "   3. Book  59387 - Predicted: 5.00 stars\n",
      "   4. Book  15362 - Predicted: 4.86 stars\n",
      "   5. Book  19410 - Predicted: 4.86 stars\n",
      "   6. Book    270 - Predicted: 4.75 stars\n",
      "   7. Book  20658 - Predicted: 4.75 stars\n",
      "   8. Book    665 - Predicted: 4.50 stars\n",
      "   9. Book  14479 - Predicted: 4.50 stars\n",
      "  10. Book  19488 - Predicted: 4.50 stars\n",
      "Model Summary:\n",
      "Dataset: 144,343 interactions\n",
      "Users: 20,780\n",
      "Books: 7,208\n",
      "Model size: 2.2 MB\n",
      "Prediction function: predict_rating(user_id, book_id, k=25)\n",
      "Recommendation function: get_recommendations(user_id, n=10, k=25)\n"
     ]
    }
   ],
   "source": [
    "# STEP 11: Define Prediction Function & Test\n",
    "\n",
    "def predict_rating(user_id, book_id, k=25):\n",
    "    \"\"\"Predict rating for a user-book pair\"\"\"\n",
    "    if user_id not in user_to_idx or book_id not in book_to_idx:\n",
    "        return book_means.mean() if len(book_means) > 0 else 3.0\n",
    "    \n",
    "    user_idx = user_to_idx[user_id]\n",
    "    book_idx = book_to_idx[book_id]\n",
    "    \n",
    "    # Get user's rated books\n",
    "    user_ratings = rating_matrix[user_idx].toarray().flatten()\n",
    "    rated_mask = user_ratings > 0\n",
    "    \n",
    "    if not rated_mask.any():\n",
    "        return book_means[book_idx]\n",
    "    \n",
    "    # Get similarities to target book\n",
    "    similarities = item_similarity_sparse[book_idx].toarray().flatten()\n",
    "    similarities = similarities * rated_mask\n",
    "    \n",
    "    # Get top-k neighbors\n",
    "    neighbor_indices = np.argsort(np.abs(similarities))[-k:]\n",
    "    neighbor_indices = neighbor_indices[similarities[neighbor_indices] != 0]\n",
    "    \n",
    "    if len(neighbor_indices) == 0:\n",
    "        return book_means[book_idx]\n",
    "    \n",
    "    # Weighted average prediction\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "    \n",
    "    for idx in neighbor_indices:\n",
    "        sim = similarities[idx]\n",
    "        rating = user_ratings[idx]\n",
    "        baseline = book_means[idx]\n",
    "        numerator += sim * (rating - baseline)\n",
    "        denominator += abs(sim)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return book_means[book_idx]\n",
    "    \n",
    "    return np.clip(book_means[book_idx] + numerator / denominator, 0, 5)\n",
    "\n",
    "\n",
    "def get_recommendations(user_id, n=10, k=25):\n",
    "    \"\"\"Get top N recommendations for a user\"\"\"\n",
    "    if user_id not in user_to_idx:\n",
    "        # Cold start: return most popular books\n",
    "        top_books = np.argsort(book_means)[-n:][::-1]\n",
    "        return [(idx_to_book[idx], book_means[idx]) for idx in top_books]\n",
    "    \n",
    "    user_idx = user_to_idx[user_id]\n",
    "    \n",
    "    # Get rated books\n",
    "    user_ratings = rating_matrix[user_idx].toarray().flatten()\n",
    "    rated_books = set(np.where(user_ratings > 0)[0])\n",
    "    \n",
    "    # Get unrated books\n",
    "    all_books = set(range(len(book_means)))\n",
    "    unrated_books = list(all_books - rated_books)\n",
    "    \n",
    "    # Predict ratings\n",
    "    predictions = []\n",
    "    for book_idx in unrated_books:\n",
    "        book_id = idx_to_book[book_idx]\n",
    "        pred_rating = predict_rating(user_id, book_id, k=k)\n",
    "        predictions.append((book_id, pred_rating))\n",
    "    \n",
    "    # Sort and return top N\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return predictions[:n]\n",
    "\n",
    "\n",
    "# Test with a random user\n",
    "test_user = list(user_to_idx.keys())[0]\n",
    "print(f\"\\nTest User: {test_user}\")\n",
    "\n",
    "# Get user's actual ratings\n",
    "user_idx = user_to_idx[test_user]\n",
    "user_ratings = rating_matrix[user_idx].toarray().flatten()\n",
    "rated_indices = np.where(user_ratings > 0)[0]\n",
    "rated_books = [(idx_to_book[idx], user_ratings[idx]) for idx in rated_indices]\n",
    "\n",
    "print(f\"\\nUser has rated {len(rated_books)} books\")\n",
    "print(\"Sample ratings:\")\n",
    "for book_id, rating in rated_books[:5]:\n",
    "    print(f\"  Book {book_id}: {rating:.1f} stars\")\n",
    "\n",
    "# Test prediction on a rated book\n",
    "if len(rated_books) > 0:\n",
    "    test_book = rated_books[0][0]\n",
    "    actual_rating = rated_books[0][1]\n",
    "    predicted = predict_rating(test_user, test_book, k=25)\n",
    "    print(f\"\\nPrediction test:\")\n",
    "    print(f\"  Book {test_book}\")\n",
    "    print(f\"  Actual rating: {actual_rating:.1f}\")\n",
    "    print(f\"  Predicted rating: {predicted:.2f}\")\n",
    "\n",
    "# Get recommendations\n",
    "print(f\"\\nTop 10 Recommendations for User {test_user}:\")\n",
    "recs = get_recommendations(test_user, n=10, k=25)\n",
    "for i, (book_id, pred_rating) in enumerate(recs, 1):\n",
    "    print(f\"  {i:2d}. Book {book_id:6d} - Predicted: {pred_rating:.2f} stars\")\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "print(f\"Dataset: {len(data):,} interactions\")\n",
    "print(f\"Users: {len(users):,}\")\n",
    "print(f\"Books: {len(books):,}\")\n",
    "print(f\"Model size: {file_size:.1f} MB\")\n",
    "print(f\"Prediction function: predict_rating(user_id, book_id, k=25)\")\n",
    "print(f\"Recommendation function: get_recommendations(user_id, n=10, k=25)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a3030",
   "metadata": {},
   "source": [
    "=========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d87c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering books with minimum 20 interactions...\n"
     ]
    }
   ],
   "source": [
    "# print(\"Filtering books with minimum 20 interactions...\")\n",
    "# data = original_data.groupby('book_id').filter(lambda x: len(x) >= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c7a9697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered dataset:\n",
      "Total interactions: 115,346,986\n",
      "Unique users: 254,194\n",
      "Unique books: 578,590\n",
      "Sparsity: 99.92%\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Filtered dataset:\")\n",
    "# print(f\"Total interactions: {len(data):,}\")\n",
    "# print(f\"Unique users: {data['user_id'].nunique():,}\")\n",
    "# print(f\"Unique books: {data['book_id'].nunique():,}\")\n",
    "# print(f\"Sparsity: {100 * (1 - len(data) / (data['user_id'].nunique() * data['book_id'].nunique())):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39249265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 254,194\n",
      "Number of books: 578,590\n",
      "Rating matrix shape: (254194, 578590)\n",
      "Non-zero entries: 115,346,986\n",
      "Matrix memory: ~0.43 GB\n"
     ]
    }
   ],
   "source": [
    "#creating sparse rating matrix\n",
    "\n",
    "# Create index mappings\n",
    "users = sorted(data['user_id'].unique())\n",
    "books = sorted(data['book_id'].unique())\n",
    "\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "book_to_idx = {book: idx for idx, book in enumerate(books)}\n",
    "idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "idx_to_book = {idx: book for book, idx in book_to_idx.items()}\n",
    "\n",
    "print(f\"Number of users: {len(users):,}\")\n",
    "print(f\"Number of books: {len(books):,}\")\n",
    "\n",
    "# Create sparse matrix\n",
    "row_indices = [user_to_idx[uid] for uid in data['user_id']]\n",
    "col_indices = [book_to_idx[bid] for bid in data['book_id']]\n",
    "ratings = data['rating'].values\n",
    "\n",
    "rating_matrix = csr_matrix(\n",
    "    (ratings, (row_indices, col_indices)),\n",
    "    shape=(len(users), len(books)),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "print(f\"Rating matrix shape: {rating_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {rating_matrix.nnz:,}\")\n",
    "print(f\"Matrix memory: ~{rating_matrix.data.nbytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "765cd1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean user rating: nan\n",
      "Starting to center ratings...\n",
      "  Centered 50,000 / 254,194 users (19.7%)...\n",
      "  Centered 100,000 / 254,194 users (39.3%)...\n",
      "  Centered 150,000 / 254,194 users (59.0%)...\n",
      "  Centered 200,000 / 254,194 users (78.7%)...\n",
      "  Centered 250,000 / 254,194 users (98.4%)...\n",
      "Ratings centered successfully ---> DONE\n"
     ]
    }
   ],
   "source": [
    "# Computing user means and centering ratings\n",
    "\n",
    "# Compute user means\n",
    "user_rating_counts = np.diff(rating_matrix.indptr)\n",
    "user_rating_sums = np.array(rating_matrix.sum(axis=1)).flatten()\n",
    "user_means = np.divide(user_rating_sums, user_rating_counts, \n",
    "                      out=np.zeros_like(user_rating_sums), \n",
    "                      where=user_rating_counts!=0)\n",
    "\n",
    "print(f\"Mean user rating: {user_means.mean():.3f}\")\n",
    "print(f\"Starting to center ratings...\")\n",
    "\n",
    "# Center ratings\n",
    "rating_matrix_centered = rating_matrix.copy().astype(np.float32)\n",
    "\n",
    "for user_idx in range(rating_matrix_centered.shape[0]):\n",
    "    start = rating_matrix_centered.indptr[user_idx]\n",
    "    end = rating_matrix_centered.indptr[user_idx + 1]\n",
    "    \n",
    "    if end > start:\n",
    "        rating_matrix_centered.data[start:end] -= user_means[user_idx]\n",
    "    \n",
    "    # Progress indicator every 50K users\n",
    "    if (user_idx + 1) % 50000 == 0:\n",
    "        print(f\"  Centered {user_idx + 1:,} / {len(users):,} users ({100*(user_idx+1)/len(users):.1f}%)...\")\n",
    "\n",
    "print(\"Ratings centered successfully ---> DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "976853ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint to: D:\\GoodreadsData_SPARSE\\checkpoint_before_similarity.pkl\n",
      "Checkpoint saved successfully!\n",
      "File size: 1.75 GB\n"
     ]
    }
   ],
   "source": [
    "#SAVING CHECKPOINT!\n",
    "\n",
    "folder = r\"D:\\GoodreadsData_SPARSE\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "checkpoint_data = {\n",
    "    'rating_matrix': rating_matrix,\n",
    "    'rating_matrix_centered': rating_matrix_centered,\n",
    "    'user_means': user_means,\n",
    "    'user_to_idx': user_to_idx,\n",
    "    'book_to_idx': book_to_idx,\n",
    "    'idx_to_user': idx_to_user,\n",
    "    'idx_to_book': idx_to_book,\n",
    "    'users': users,\n",
    "    'books': books\n",
    "}\n",
    "\n",
    "checkpoint_file = os.path.join(folder, 'checkpoint_before_similarity.pkl')\n",
    "\n",
    "print(f\"Saving checkpoint to: {checkpoint_file}\")\n",
    "with open(checkpoint_file, 'wb') as f:\n",
    "    pickle.dump(checkpoint_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Checkpoint saved successfully!\")\n",
    "print(f\"File size: {os.path.getsize(checkpoint_file) / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35094eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Loading checkpoint...\")\n",
    "\n",
    "# folder = r\"D:\\GoodreadsData\"\n",
    "# checkpoint_file = os.path.join(folder, 'checkpoint_before_similarity.pkl')\n",
    "\n",
    "# with open(checkpoint_file, 'rb') as f:\n",
    "#     checkpoint_data = pickle.load(f)\n",
    "\n",
    "# # Restore all variables\n",
    "# rating_matrix = checkpoint_data['rating_matrix']\n",
    "# rating_matrix_centered = checkpoint_data['rating_matrix_centered']\n",
    "# user_means = checkpoint_data['user_means']\n",
    "# user_to_idx = checkpoint_data['user_to_idx']\n",
    "# book_to_idx = checkpoint_data['book_to_idx']\n",
    "# idx_to_user = checkpoint_data['idx_to_user']\n",
    "# idx_to_book = checkpoint_data['idx_to_book']\n",
    "# users = checkpoint_data['users']\n",
    "# books = checkpoint_data['books']\n",
    "\n",
    "# print(\"âœ“ Checkpoint loaded successfully!\")\n",
    "# print(f\"  Rating matrix: {rating_matrix.shape}\")\n",
    "# print(f\"  Users: {len(users):,}\")\n",
    "# print(f\"  Books: {len(books):,}\")\n",
    "# print(\"\\nYou can now continue with Step 4!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a48e1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in rating_matrix_centered: 220\n",
      "Cleaning NaN values (replacing with 0)...\n",
      "NaN values cleaned!\n",
      "NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for NaN values\n",
    "print(f\"NaN values in rating_matrix_centered: {np.isnan(rating_matrix_centered.data).sum():,}\")\n",
    "\n",
    "if np.isnan(rating_matrix_centered.data).any():\n",
    "    print(\"Cleaning NaN values (replacing with 0)...\")\n",
    "    rating_matrix_centered.data = np.nan_to_num(rating_matrix_centered.data, nan=0.0)\n",
    "    print(\"NaN values cleaned!\")\n",
    "else:\n",
    "    print(\"No NaN values found!\")\n",
    "\n",
    "print(f\"NaN count: {np.isnan(rating_matrix_centered.data).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "473ec0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero entries: 114,903,391\n"
     ]
    }
   ],
   "source": [
    "rating_matrix_centered.eliminate_zeros()\n",
    "print(f\"Non-zero entries: {rating_matrix_centered.nnz:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3e61ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT OF MEMORY!\n",
      "Suggestion: Increase threshold to 30 and restart\n"
     ]
    }
   ],
   "source": [
    "#Computing adjusted cosine similarity\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    item_similarity_sparse = cosine_similarity(\n",
    "        rating_matrix_centered.T, \n",
    "        dense_output=False\n",
    "    )\n",
    "    \n",
    "    elapsed = datetime.now() - start_time\n",
    "    print(f\"DONEE! Similarity computed in {elapsed}\")\n",
    "    print(f\"Shape: {item_similarity_sparse.shape}\")\n",
    "    print(f\"Non-zero similarities: {item_similarity_sparse.nnz:,}\")\n",
    "    print(f\"Memory: ~{item_similarity_sparse.data.nbytes / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # Save immediately\n",
    "    folder = r\"D:\\GoodreadsData_SPARSE\"\n",
    "    with open(os.path.join(folder, 'similarity_matrix_raw.pkl'), 'wb') as f:\n",
    "        pickle.dump(item_similarity_sparse, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Similarity matrix saved\")\n",
    "    \n",
    "except MemoryError:\n",
    "    print(\"OUT OF MEMORY!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf503b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "118d71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 106,826,056 interactions, 306,020 books\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.39 GiB for an array with shape (3, 106825306) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter filtering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m interactions, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m books\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Keep users with at least 10 interactions (active users)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter filtering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m interactions, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m users\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# If still too large, sample to target size\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1757\u001b[0m, in \u001b[0;36mDataFrameGroupBy.filter\u001b[1;34m(self, func, dropna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1751\u001b[0m         \u001b[38;5;66;03m# non scalars aren't allowed\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1753\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter function returned a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(res)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut expected a scalar bool\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1755\u001b[0m         )\n\u001b[1;32m-> 1757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_filter(indices, dropna)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1590\u001b[0m, in \u001b[0;36mGroupBy._apply_filter\u001b[1;34m(self, indices, dropna)\u001b[0m\n\u001b[0;32m   1588\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(np\u001b[38;5;241m.\u001b[39mconcatenate(indices))\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropna:\n\u001b[1;32m-> 1590\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mindex), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3909\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3833\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3834\u001b[0m \u001b[38;5;124;03mReturn the elements in the given *positional* indices along an axis.\u001b[39;00m\n\u001b[0;32m   3835\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3904\u001b[0m \u001b[38;5;124;03m3    lion  mammal       80.5\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3907\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m-> 3909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices, axis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3933\u001b[0m     indices,\n\u001b[0;32m   3934\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3935\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3936\u001b[0m     convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[0;32m   3937\u001b[0m )\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    964\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    965\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    966\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    967\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    968\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    969\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:747\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    741\u001b[0m         indexer,\n\u001b[0;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[0;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    753\u001b[0m             ),\n\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n\u001b[0;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    741\u001b[0m         indexer,\n\u001b[0;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[0;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    753\u001b[0m             ),\n\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n\u001b[0;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    946\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.39 GiB for an array with shape (3, 106825306) and data type float64"
     ]
    }
   ],
   "source": [
    "# SAMPLING STRATEGY: Hybrid (Popular Books + Active Users)\n",
    "\n",
    "# Keep books with at least 50 interactions (stricter filter)\n",
    "data = data.groupby('book_id').filter(lambda x: len(x) >= 50)\n",
    "print(f\"After filtering: {len(data):,} interactions, {data['book_id'].nunique():,} books\")\n",
    "\n",
    "# Keep users with at least 10 interactions (active users)\n",
    "data = data.groupby('user_id').filter(lambda x: len(x) >= 10)\n",
    "print(f\"After filtering: {len(data):,} interactions, {data['user_id'].nunique():,} users\")\n",
    "\n",
    "# If still too large, sample to target size\n",
    "target_max = 1_000_000  # 1M interactions\n",
    "if len(data) > target_max:\n",
    "    print(f\"Dataset still large ({len(data):,}), sampling to {target_max:,}...\")\n",
    "    sample_fraction = target_max / len(data)\n",
    "    data = data.sample(frac=sample_fraction, random_state=42)\n",
    "    print(f\"Sampled to: {len(data):,} interactions\")\n",
    "\n",
    "print(\"FINAL DATASET:\")\n",
    "print(f\"Total interactions: {len(data):,}\")\n",
    "print(f\"Unique books: {data['movie_id'].nunique():,}\")\n",
    "print(f\"Unique users: {data['user_id'].nunique():,}\")\n",
    "print(f\"Sparsity: {100 * (1 - len(data) / (data['user_id'].nunique() * data['movie_id'].nunique())):.2f}%\")\n",
    "print(f\"Avg interactions per book: {len(data) / data['movie_id'].nunique():.1f}\")\n",
    "print(f\"Avg interactions per user: {len(data) / data['user_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0499b15",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced368b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoids calculating similarity for millions of books\n",
    "data = original_data.groupby('movie_id').filter(lambda x: len(x) >= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1d95ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  is_read  rating  is_reviewed\n",
       "0        0       948      1.0     5.0          0.0\n",
       "1        0       947      1.0     5.0          1.0\n",
       "2        0       946      1.0     5.0          0.0\n",
       "3        0       945      1.0     5.0          0.0\n",
       "4        0       944      1.0     5.0          0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a706dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444259"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.movie_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0fac6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112120510"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b9d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 123731803\n",
      "After filtering: 112120510\n"
     ]
    }
   ],
   "source": [
    "print(\"Before filtering:\", len(original_data))\n",
    "print(\"After filtering:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a03467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 254191\n",
      "Books: 444259\n",
      "Interactions: 112120510\n"
     ]
    }
   ],
   "source": [
    "print(\"Users:\", data.user_id.nunique())\n",
    "print(\"Books:\", data.movie_id.nunique())\n",
    "print(\"Interactions:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "124b067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_movie = data.groupby('user_id')['movie_id'].apply(list).to_dict()\n",
    "movie_to_user = data.groupby('movie_id')['user_id'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080c7269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_to_movie[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0919966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_ratings = data.groupby('user_id')['rating'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "698f33c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_to_ratings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25cc6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Replace this path with your folder on D: drive\n",
    "folder = r\"D:\\GoodreadsData\"\n",
    "\n",
    "# Make sure the folder exists\n",
    "import os\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Save dictionaries\n",
    "with open(os.path.join(folder, \"user_to_movie.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(user_to_movie, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(folder, \"user_to_ratings.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(user_to_ratings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(folder, \"movie_to_user.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(movie_to_user, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd89380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_movie_rating = (\n",
    "    data.groupby('user_id')\n",
    "        .apply(lambda x: list(zip(x['movie_id'], x['rating'])))\n",
    "        .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de957213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(948, 5.0),\n",
       " (947, 5.0),\n",
       " (946, 5.0),\n",
       " (945, 5.0),\n",
       " (944, 5.0),\n",
       " (943, 5.0),\n",
       " (942, 5.0),\n",
       " (941, 5.0),\n",
       " (940, 5.0),\n",
       " (939, 5.0),\n",
       " (938, 5.0),\n",
       " (937, 4.0),\n",
       " (936, 4.0),\n",
       " (935, 4.0),\n",
       " (934, 5.0),\n",
       " (933, 4.0),\n",
       " (932, 4.0),\n",
       " (931, 5.0),\n",
       " (930, 2.0),\n",
       " (929, 4.0),\n",
       " (928, 4.0),\n",
       " (927, 5.0),\n",
       " (924, 5.0),\n",
       " (923, 5.0),\n",
       " (922, 5.0),\n",
       " (921, 4.0),\n",
       " (920, 5.0),\n",
       " (919, 5.0),\n",
       " (918, 5.0),\n",
       " (917, 3.0),\n",
       " (916, 5.0),\n",
       " (915, 5.0),\n",
       " (914, 4.0),\n",
       " (912, 5.0),\n",
       " (910, 0.0),\n",
       " (909, 4.0),\n",
       " (908, 4.0),\n",
       " (907, 0.0),\n",
       " (906, 0.0),\n",
       " (905, 4.0),\n",
       " (904, 0.0),\n",
       " (903, 5.0),\n",
       " (901, 4.0),\n",
       " (900, 4.0),\n",
       " (899, 4.0),\n",
       " (898, 3.0),\n",
       " (897, 5.0),\n",
       " (896, 0.0),\n",
       " (895, 5.0),\n",
       " (893, 4.0),\n",
       " (892, 5.0),\n",
       " (891, 4.0),\n",
       " (890, 5.0),\n",
       " (889, 5.0),\n",
       " (888, 4.0),\n",
       " (887, 0.0),\n",
       " (886, 3.0),\n",
       " (885, 0.0),\n",
       " (884, 0.0),\n",
       " (883, 4.0),\n",
       " (882, 5.0),\n",
       " (881, 0.0),\n",
       " (880, 5.0),\n",
       " (879, 5.0),\n",
       " (878, 4.0),\n",
       " (877, 5.0),\n",
       " (876, 4.0),\n",
       " (875, 4.0),\n",
       " (874, 3.0),\n",
       " (873, 4.0),\n",
       " (872, 3.0),\n",
       " (871, 2.0),\n",
       " (870, 3.0),\n",
       " (869, 3.0),\n",
       " (868, 0.0),\n",
       " (867, 3.0),\n",
       " (866, 4.0),\n",
       " (865, 5.0),\n",
       " (864, 0.0),\n",
       " (863, 4.0),\n",
       " (862, 5.0),\n",
       " (861, 5.0),\n",
       " (860, 5.0),\n",
       " (859, 4.0),\n",
       " (858, 5.0),\n",
       " (857, 0.0),\n",
       " (856, 4.0),\n",
       " (855, 5.0),\n",
       " (854, 4.0),\n",
       " (853, 5.0),\n",
       " (852, 0.0),\n",
       " (851, 0.0),\n",
       " (850, 5.0),\n",
       " (849, 3.0),\n",
       " (848, 3.0),\n",
       " (847, 5.0),\n",
       " (846, 5.0),\n",
       " (845, 4.0),\n",
       " (844, 3.0),\n",
       " (843, 3.0),\n",
       " (842, 3.0),\n",
       " (839, 5.0),\n",
       " (838, 5.0),\n",
       " (837, 4.0),\n",
       " (835, 0.0),\n",
       " (834, 4.0),\n",
       " (833, 2.0),\n",
       " (832, 4.0),\n",
       " (831, 5.0),\n",
       " (830, 4.0),\n",
       " (829, 5.0),\n",
       " (828, 5.0),\n",
       " (827, 4.0),\n",
       " (826, 4.0),\n",
       " (825, 5.0),\n",
       " (824, 5.0),\n",
       " (823, 3.0),\n",
       " (822, 0.0),\n",
       " (821, 5.0),\n",
       " (820, 4.0),\n",
       " (819, 4.0),\n",
       " (818, 3.0),\n",
       " (817, 3.0),\n",
       " (816, 4.0),\n",
       " (815, 0.0),\n",
       " (812, 4.0),\n",
       " (811, 5.0),\n",
       " (810, 2.0),\n",
       " (809, 5.0),\n",
       " (808, 3.0),\n",
       " (807, 4.0),\n",
       " (805, 4.0),\n",
       " (804, 5.0),\n",
       " (803, 4.0),\n",
       " (802, 3.0),\n",
       " (801, 5.0),\n",
       " (799, 4.0),\n",
       " (798, 3.0),\n",
       " (797, 3.0),\n",
       " (796, 0.0),\n",
       " (795, 4.0),\n",
       " (792, 0.0),\n",
       " (791, 0.0),\n",
       " (790, 5.0),\n",
       " (789, 5.0),\n",
       " (788, 4.0),\n",
       " (787, 5.0),\n",
       " (786, 5.0),\n",
       " (785, 2.0),\n",
       " (784, 5.0),\n",
       " (783, 4.0),\n",
       " (781, 4.0),\n",
       " (780, 4.0),\n",
       " (779, 4.0),\n",
       " (776, 0.0),\n",
       " (774, 0.0),\n",
       " (773, 3.0),\n",
       " (772, 5.0),\n",
       " (771, 4.0),\n",
       " (770, 4.0),\n",
       " (769, 0.0),\n",
       " (768, 5.0),\n",
       " (767, 4.0),\n",
       " (766, 3.0),\n",
       " (765, 5.0),\n",
       " (764, 5.0),\n",
       " (763, 0.0),\n",
       " (762, 4.0),\n",
       " (761, 5.0),\n",
       " (760, 3.0),\n",
       " (759, 4.0),\n",
       " (758, 4.0),\n",
       " (757, 3.0),\n",
       " (756, 0.0),\n",
       " (754, 0.0),\n",
       " (753, 0.0),\n",
       " (750, 5.0),\n",
       " (749, 3.0),\n",
       " (748, 4.0),\n",
       " (747, 3.0),\n",
       " (746, 3.0),\n",
       " (745, 2.0),\n",
       " (744, 1.0),\n",
       " (743, 3.0),\n",
       " (742, 5.0),\n",
       " (741, 4.0),\n",
       " (740, 2.0),\n",
       " (739, 4.0),\n",
       " (738, 0.0),\n",
       " (737, 5.0),\n",
       " (736, 0.0),\n",
       " (734, 4.0),\n",
       " (733, 4.0),\n",
       " (732, 0.0),\n",
       " (731, 4.0),\n",
       " (724, 0.0),\n",
       " (723, 5.0),\n",
       " (722, 0.0),\n",
       " (721, 5.0),\n",
       " (720, 0.0),\n",
       " (719, 3.0),\n",
       " (718, 0.0),\n",
       " (717, 0.0),\n",
       " (716, 4.0),\n",
       " (715, 5.0),\n",
       " (714, 0.0),\n",
       " (713, 5.0),\n",
       " (712, 5.0),\n",
       " (711, 5.0),\n",
       " (710, 0.0),\n",
       " (708, 0.0),\n",
       " (707, 4.0),\n",
       " (706, 5.0),\n",
       " (704, 5.0),\n",
       " (703, 4.0),\n",
       " (702, 5.0),\n",
       " (701, 0.0),\n",
       " (700, 5.0),\n",
       " (699, 4.0),\n",
       " (698, 4.0),\n",
       " (697, 4.0),\n",
       " (696, 5.0),\n",
       " (695, 4.0),\n",
       " (693, 0.0),\n",
       " (692, 0.0),\n",
       " (691, 4.0),\n",
       " (690, 3.0),\n",
       " (689, 5.0),\n",
       " (688, 0.0),\n",
       " (685, 4.0),\n",
       " (684, 4.0),\n",
       " (683, 0.0),\n",
       " (682, 0.0),\n",
       " (681, 5.0),\n",
       " (680, 5.0),\n",
       " (679, 5.0),\n",
       " (678, 5.0),\n",
       " (677, 5.0),\n",
       " (676, 5.0),\n",
       " (675, 5.0),\n",
       " (673, 5.0),\n",
       " (671, 4.0),\n",
       " (670, 5.0),\n",
       " (669, 5.0),\n",
       " (668, 5.0),\n",
       " (667, 3.0),\n",
       " (666, 0.0),\n",
       " (665, 3.0),\n",
       " (664, 3.0),\n",
       " (663, 3.0),\n",
       " (662, 3.0),\n",
       " (661, 3.0),\n",
       " (660, 3.0),\n",
       " (659, 3.0),\n",
       " (658, 3.0),\n",
       " (657, 3.0),\n",
       " (656, 3.0),\n",
       " (655, 3.0),\n",
       " (654, 3.0),\n",
       " (653, 0.0),\n",
       " (652, 3.0),\n",
       " (651, 0.0),\n",
       " (650, 0.0),\n",
       " (649, 4.0),\n",
       " (648, 4.0),\n",
       " (647, 0.0),\n",
       " (646, 3.0),\n",
       " (644, 4.0),\n",
       " (643, 0.0),\n",
       " (642, 5.0),\n",
       " (640, 0.0),\n",
       " (639, 0.0),\n",
       " (638, 4.0),\n",
       " (637, 0.0),\n",
       " (636, 5.0),\n",
       " (635, 5.0),\n",
       " (634, 5.0),\n",
       " (633, 5.0),\n",
       " (632, 0.0),\n",
       " (631, 0.0),\n",
       " (630, 0.0),\n",
       " (629, 0.0),\n",
       " (628, 0.0),\n",
       " (627, 4.0),\n",
       " (626, 0.0),\n",
       " (625, 0.0),\n",
       " (624, 5.0),\n",
       " (623, 4.0),\n",
       " (622, 0.0),\n",
       " (621, 0.0),\n",
       " (620, 5.0),\n",
       " (619, 4.0),\n",
       " (618, 0.0),\n",
       " (617, 0.0),\n",
       " (616, 0.0),\n",
       " (615, 0.0),\n",
       " (614, 3.0),\n",
       " (613, 5.0),\n",
       " (612, 0.0),\n",
       " (611, 3.0),\n",
       " (610, 0.0),\n",
       " (609, 0.0),\n",
       " (608, 5.0),\n",
       " (607, 0.0),\n",
       " (605, 0.0),\n",
       " (603, 5.0),\n",
       " (602, 0.0),\n",
       " (601, 3.0),\n",
       " (600, 4.0),\n",
       " (599, 0.0),\n",
       " (598, 5.0),\n",
       " (597, 0.0),\n",
       " (596, 0.0),\n",
       " (594, 5.0),\n",
       " (592, 0.0),\n",
       " (591, 0.0),\n",
       " (590, 5.0),\n",
       " (588, 5.0),\n",
       " (587, 0.0),\n",
       " (586, 4.0),\n",
       " (584, 5.0),\n",
       " (583, 0.0),\n",
       " (582, 4.0),\n",
       " (581, 4.0),\n",
       " (580, 5.0),\n",
       " (579, 0.0),\n",
       " (578, 0.0),\n",
       " (577, 0.0),\n",
       " (576, 0.0),\n",
       " (575, 0.0),\n",
       " (574, 4.0),\n",
       " (573, 5.0),\n",
       " (572, 0.0),\n",
       " (570, 0.0),\n",
       " (569, 0.0),\n",
       " (568, 4.0),\n",
       " (567, 4.0),\n",
       " (566, 5.0),\n",
       " (565, 4.0),\n",
       " (564, 4.0),\n",
       " (563, 4.0),\n",
       " (562, 4.0),\n",
       " (561, 0.0),\n",
       " (560, 0.0),\n",
       " (559, 0.0),\n",
       " (558, 0.0),\n",
       " (557, 3.0),\n",
       " (556, 0.0),\n",
       " (555, 3.0),\n",
       " (554, 5.0),\n",
       " (553, 0.0),\n",
       " (552, 0.0),\n",
       " (551, 0.0),\n",
       " (550, 4.0),\n",
       " (548, 0.0),\n",
       " (547, 5.0),\n",
       " (546, 4.0),\n",
       " (545, 3.0),\n",
       " (544, 0.0),\n",
       " (543, 0.0),\n",
       " (542, 0.0),\n",
       " (541, 3.0),\n",
       " (540, 0.0),\n",
       " (539, 0.0),\n",
       " (538, 0.0),\n",
       " (537, 5.0),\n",
       " (536, 5.0),\n",
       " (535, 5.0),\n",
       " (534, 0.0),\n",
       " (533, 0.0),\n",
       " (532, 0.0),\n",
       " (531, 4.0),\n",
       " (530, 3.0),\n",
       " (529, 0.0),\n",
       " (528, 0.0),\n",
       " (527, 0.0),\n",
       " (526, 0.0),\n",
       " (525, 0.0),\n",
       " (524, 5.0),\n",
       " (523, 0.0),\n",
       " (522, 0.0),\n",
       " (521, 0.0),\n",
       " (520, 3.0),\n",
       " (517, 0.0),\n",
       " (516, 0.0),\n",
       " (515, 3.0),\n",
       " (514, 0.0),\n",
       " (512, 5.0),\n",
       " (511, 5.0),\n",
       " (510, 0.0),\n",
       " (509, 4.0),\n",
       " (507, 4.0),\n",
       " (506, 0.0),\n",
       " (504, 5.0),\n",
       " (503, 5.0),\n",
       " (502, 0.0),\n",
       " (501, 0.0),\n",
       " (500, 0.0),\n",
       " (499, 0.0),\n",
       " (498, 0.0),\n",
       " (497, 2.0),\n",
       " (496, 3.0),\n",
       " (495, 0.0),\n",
       " (494, 0.0),\n",
       " (493, 3.0),\n",
       " (492, 0.0),\n",
       " (491, 0.0),\n",
       " (490, 5.0),\n",
       " (489, 0.0),\n",
       " (488, 3.0),\n",
       " (486, 0.0),\n",
       " (485, 4.0),\n",
       " (484, 0.0),\n",
       " (483, 0.0),\n",
       " (482, 4.0),\n",
       " (481, 0.0),\n",
       " (480, 4.0),\n",
       " (479, 0.0),\n",
       " (478, 0.0),\n",
       " (477, 0.0),\n",
       " (476, 0.0),\n",
       " (475, 0.0),\n",
       " (474, 0.0),\n",
       " (473, 0.0),\n",
       " (472, 5.0),\n",
       " (471, 0.0),\n",
       " (470, 0.0),\n",
       " (469, 4.0),\n",
       " (468, 0.0),\n",
       " (467, 0.0),\n",
       " (466, 0.0),\n",
       " (464, 0.0),\n",
       " (463, 0.0),\n",
       " (462, 0.0),\n",
       " (461, 5.0),\n",
       " (460, 5.0),\n",
       " (459, 5.0),\n",
       " (458, 5.0),\n",
       " (457, 5.0),\n",
       " (456, 0.0),\n",
       " (455, 0.0),\n",
       " (454, 0.0),\n",
       " (453, 4.0),\n",
       " (452, 5.0),\n",
       " (451, 5.0),\n",
       " (450, 0.0),\n",
       " (449, 0.0),\n",
       " (448, 0.0),\n",
       " (447, 0.0),\n",
       " (446, 4.0),\n",
       " (445, 0.0),\n",
       " (444, 5.0),\n",
       " (443, 5.0),\n",
       " (442, 5.0),\n",
       " (441, 5.0),\n",
       " (440, 5.0),\n",
       " (439, 5.0),\n",
       " (438, 5.0),\n",
       " (437, 0.0),\n",
       " (436, 0.0),\n",
       " (434, 0.0),\n",
       " (433, 0.0),\n",
       " (432, 4.0),\n",
       " (431, 0.0),\n",
       " (430, 5.0),\n",
       " (429, 2.0),\n",
       " (428, 4.0),\n",
       " (427, 5.0),\n",
       " (425, 0.0),\n",
       " (424, 0.0),\n",
       " (423, 5.0),\n",
       " (422, 0.0),\n",
       " (421, 4.0),\n",
       " (420, 4.0),\n",
       " (419, 0.0),\n",
       " (418, 0.0),\n",
       " (417, 4.0),\n",
       " (416, 0.0),\n",
       " (415, 5.0),\n",
       " (414, 0.0),\n",
       " (413, 0.0),\n",
       " (412, 0.0),\n",
       " (411, 0.0),\n",
       " (410, 5.0),\n",
       " (409, 0.0),\n",
       " (408, 3.0),\n",
       " (407, 0.0),\n",
       " (406, 5.0),\n",
       " (405, 5.0),\n",
       " (404, 5.0),\n",
       " (403, 3.0),\n",
       " (402, 0.0),\n",
       " (401, 5.0),\n",
       " (400, 5.0),\n",
       " (399, 5.0),\n",
       " (398, 0.0),\n",
       " (397, 0.0),\n",
       " (394, 0.0),\n",
       " (393, 0.0),\n",
       " (392, 3.0),\n",
       " (391, 5.0),\n",
       " (390, 0.0),\n",
       " (389, 0.0),\n",
       " (388, 0.0),\n",
       " (387, 4.0),\n",
       " (385, 0.0),\n",
       " (384, 5.0),\n",
       " (383, 4.0),\n",
       " (382, 0.0),\n",
       " (381, 3.0),\n",
       " (380, 5.0),\n",
       " (379, 0.0),\n",
       " (378, 3.0),\n",
       " (377, 4.0),\n",
       " (376, 0.0),\n",
       " (375, 0.0),\n",
       " (374, 0.0),\n",
       " (373, 0.0),\n",
       " (372, 0.0),\n",
       " (371, 0.0),\n",
       " (370, 0.0),\n",
       " (369, 0.0),\n",
       " (368, 0.0),\n",
       " (367, 5.0),\n",
       " (365, 5.0),\n",
       " (361, 4.0),\n",
       " (360, 0.0),\n",
       " (359, 0.0),\n",
       " (358, 0.0),\n",
       " (357, 5.0),\n",
       " (356, 5.0),\n",
       " (355, 5.0),\n",
       " (354, 5.0),\n",
       " (353, 5.0),\n",
       " (352, 5.0),\n",
       " (351, 5.0),\n",
       " (350, 5.0),\n",
       " (349, 5.0),\n",
       " (348, 5.0),\n",
       " (347, 5.0),\n",
       " (346, 5.0),\n",
       " (345, 5.0),\n",
       " (344, 5.0),\n",
       " (343, 5.0),\n",
       " (342, 5.0),\n",
       " (341, 5.0),\n",
       " (340, 0.0),\n",
       " (338, 0.0),\n",
       " (337, 0.0),\n",
       " (336, 5.0),\n",
       " (335, 0.0),\n",
       " (334, 4.0),\n",
       " (332, 4.0),\n",
       " (331, 4.0),\n",
       " (329, 4.0),\n",
       " (328, 0.0),\n",
       " (327, 0.0),\n",
       " (325, 0.0),\n",
       " (324, 0.0),\n",
       " (323, 0.0),\n",
       " (322, 4.0),\n",
       " (321, 0.0),\n",
       " (320, 0.0),\n",
       " (319, 0.0),\n",
       " (318, 5.0),\n",
       " (317, 0.0),\n",
       " (316, 0.0),\n",
       " (315, 0.0),\n",
       " (314, 0.0),\n",
       " (313, 0.0),\n",
       " (311, 5.0),\n",
       " (310, 0.0),\n",
       " (309, 0.0),\n",
       " (308, 0.0),\n",
       " (307, 5.0),\n",
       " (306, 0.0),\n",
       " (305, 0.0),\n",
       " (304, 0.0),\n",
       " (303, 5.0),\n",
       " (302, 0.0),\n",
       " (301, 0.0),\n",
       " (300, 0.0),\n",
       " (299, 0.0),\n",
       " (298, 0.0),\n",
       " (297, 0.0),\n",
       " (296, 0.0),\n",
       " (295, 0.0),\n",
       " (294, 0.0),\n",
       " (293, 0.0),\n",
       " (292, 0.0),\n",
       " (291, 0.0),\n",
       " (290, 5.0),\n",
       " (289, 0.0),\n",
       " (288, 0.0),\n",
       " (287, 0.0),\n",
       " (286, 0.0),\n",
       " (285, 5.0),\n",
       " (284, 5.0),\n",
       " (283, 0.0),\n",
       " (281, 0.0),\n",
       " (279, 0.0),\n",
       " (278, 0.0),\n",
       " (277, 0.0),\n",
       " (276, 0.0),\n",
       " (275, 4.0),\n",
       " (274, 0.0),\n",
       " (273, 4.0),\n",
       " (272, 4.0),\n",
       " (271, 5.0),\n",
       " (270, 2.0),\n",
       " (269, 0.0),\n",
       " (267, 3.0),\n",
       " (266, 4.0),\n",
       " (265, 5.0),\n",
       " (264, 0.0),\n",
       " (263, 4.0),\n",
       " (262, 0.0),\n",
       " (261, 0.0),\n",
       " (260, 0.0),\n",
       " (259, 5.0),\n",
       " (258, 0.0),\n",
       " (257, 5.0),\n",
       " (256, 5.0),\n",
       " (255, 4.0),\n",
       " (254, 4.0),\n",
       " (253, 0.0),\n",
       " (252, 5.0),\n",
       " (251, 4.0),\n",
       " (250, 0.0),\n",
       " (248, 5.0),\n",
       " (247, 0.0),\n",
       " (246, 0.0),\n",
       " (245, 5.0),\n",
       " (244, 5.0),\n",
       " (243, 4.0),\n",
       " (242, 0.0),\n",
       " (241, 0.0),\n",
       " (239, 0.0),\n",
       " (238, 0.0),\n",
       " (237, 0.0),\n",
       " (236, 0.0),\n",
       " (235, 0.0),\n",
       " (234, 3.0),\n",
       " (233, 4.0),\n",
       " (232, 0.0),\n",
       " (231, 5.0),\n",
       " (230, 0.0),\n",
       " (229, 0.0),\n",
       " (228, 0.0),\n",
       " (227, 5.0),\n",
       " (226, 5.0),\n",
       " (225, 0.0),\n",
       " (224, 0.0),\n",
       " (223, 5.0),\n",
       " (222, 0.0),\n",
       " (221, 0.0),\n",
       " (220, 0.0),\n",
       " (218, 4.0),\n",
       " (217, 0.0),\n",
       " (216, 5.0),\n",
       " (215, 5.0),\n",
       " (214, 0.0),\n",
       " (213, 0.0),\n",
       " (212, 0.0),\n",
       " (211, 0.0),\n",
       " (210, 0.0),\n",
       " (209, 0.0),\n",
       " (208, 0.0),\n",
       " (207, 0.0),\n",
       " (206, 0.0),\n",
       " (205, 0.0),\n",
       " (204, 4.0),\n",
       " (203, 0.0),\n",
       " (202, 0.0),\n",
       " (201, 3.0),\n",
       " (200, 0.0),\n",
       " (199, 3.0),\n",
       " (198, 0.0),\n",
       " (197, 4.0),\n",
       " (195, 0.0),\n",
       " (194, 0.0),\n",
       " (192, 0.0),\n",
       " (191, 0.0),\n",
       " (190, 0.0),\n",
       " (189, 0.0),\n",
       " (188, 0.0),\n",
       " (186, 5.0),\n",
       " (185, 0.0),\n",
       " (184, 0.0),\n",
       " (183, 4.0),\n",
       " (182, 0.0),\n",
       " (181, 5.0),\n",
       " (180, 0.0),\n",
       " (179, 0.0),\n",
       " (178, 0.0),\n",
       " (177, 5.0),\n",
       " (176, 5.0),\n",
       " (175, 0.0),\n",
       " (174, 5.0),\n",
       " (172, 3.0),\n",
       " (171, 0.0),\n",
       " (170, 0.0),\n",
       " (168, 0.0),\n",
       " (166, 0.0),\n",
       " (165, 0.0),\n",
       " (164, 5.0),\n",
       " (163, 4.0),\n",
       " (162, 5.0),\n",
       " (161, 0.0),\n",
       " (160, 4.0),\n",
       " (159, 0.0),\n",
       " (158, 0.0),\n",
       " (157, 0.0),\n",
       " (156, 0.0),\n",
       " (155, 0.0),\n",
       " (154, 4.0),\n",
       " (153, 4.0),\n",
       " (152, 0.0),\n",
       " (151, 0.0),\n",
       " (150, 0.0),\n",
       " (149, 0.0),\n",
       " (148, 0.0),\n",
       " (145, 0.0),\n",
       " (144, 0.0),\n",
       " (143, 0.0),\n",
       " (142, 0.0),\n",
       " (141, 0.0),\n",
       " (140, 0.0),\n",
       " (139, 4.0),\n",
       " (138, 5.0),\n",
       " (137, 0.0),\n",
       " (136, 0.0),\n",
       " (135, 5.0),\n",
       " (134, 0.0),\n",
       " (133, 4.0),\n",
       " (132, 5.0),\n",
       " (131, 0.0),\n",
       " (130, 0.0),\n",
       " (129, 0.0),\n",
       " (128, 0.0),\n",
       " (127, 0.0),\n",
       " (126, 5.0),\n",
       " (125, 0.0),\n",
       " (124, 3.0),\n",
       " (123, 0.0),\n",
       " (122, 0.0),\n",
       " (121, 0.0),\n",
       " (120, 0.0),\n",
       " (119, 0.0),\n",
       " (118, 0.0),\n",
       " (117, 4.0),\n",
       " (116, 0.0),\n",
       " (115, 0.0),\n",
       " (113, 0.0),\n",
       " (112, 0.0),\n",
       " (111, 0.0),\n",
       " (110, 0.0),\n",
       " (109, 0.0),\n",
       " (108, 0.0),\n",
       " (106, 5.0),\n",
       " (105, 0.0),\n",
       " (104, 4.0),\n",
       " (103, 3.0),\n",
       " (101, 0.0),\n",
       " (100, 3.0),\n",
       " (99, 0.0),\n",
       " (98, 0.0),\n",
       " (97, 3.0),\n",
       " (96, 4.0),\n",
       " (95, 0.0),\n",
       " (93, 0.0),\n",
       " (92, 0.0),\n",
       " (90, 5.0),\n",
       " (89, 0.0),\n",
       " (88, 0.0),\n",
       " (87, 0.0),\n",
       " (86, 0.0),\n",
       " (85, 5.0),\n",
       " (84, 2.0),\n",
       " (83, 0.0),\n",
       " (82, 0.0),\n",
       " (81, 0.0),\n",
       " (80, 0.0),\n",
       " (79, 0.0),\n",
       " (78, 0.0),\n",
       " (77, 0.0),\n",
       " (76, 0.0),\n",
       " (75, 0.0),\n",
       " (74, 0.0),\n",
       " (72, 0.0),\n",
       " (71, 0.0),\n",
       " (70, 0.0),\n",
       " (69, 0.0),\n",
       " (68, 5.0),\n",
       " (67, 0.0),\n",
       " (66, 0.0),\n",
       " (65, 0.0),\n",
       " (64, 0.0),\n",
       " (63, 0.0),\n",
       " (62, 0.0),\n",
       " (61, 0.0),\n",
       " (60, 0.0),\n",
       " (59, 0.0),\n",
       " (58, 0.0),\n",
       " (57, 0.0),\n",
       " (56, 0.0),\n",
       " (55, 0.0),\n",
       " (53, 0.0),\n",
       " (52, 0.0),\n",
       " (51, 0.0),\n",
       " (50, 0.0),\n",
       " (49, 0.0),\n",
       " (48, 0.0),\n",
       " (47, 0.0),\n",
       " (46, 0.0),\n",
       " (44, 0.0),\n",
       " (43, 0.0),\n",
       " (42, 0.0),\n",
       " (41, 0.0),\n",
       " (40, 0.0),\n",
       " (39, 0.0),\n",
       " (38, 0.0),\n",
       " (37, 0.0),\n",
       " (36, 0.0),\n",
       " (35, 0.0),\n",
       " (34, 0.0),\n",
       " (33, 0.0),\n",
       " (32, 0.0),\n",
       " (31, 0.0),\n",
       " (30, 0.0),\n",
       " (29, 0.0),\n",
       " (28, 0.0),\n",
       " (27, 0.0),\n",
       " (26, 0.0),\n",
       " (25, 0.0),\n",
       " (23, 4.0),\n",
       " (22, 3.0),\n",
       " (21, 5.0),\n",
       " (20, 0.0),\n",
       " (19, 0.0),\n",
       " (18, 0.0),\n",
       " (17, 0.0),\n",
       " (16, 0.0),\n",
       " (15, 0.0),\n",
       " (14, 5.0),\n",
       " (13, 0.0),\n",
       " (12, 0.0),\n",
       " (11, 0.0),\n",
       " (10, 0.0),\n",
       " (9, 0.0),\n",
       " (8, 0.0),\n",
       " (7, 0.0),\n",
       " (6, 0.0),\n",
       " (5, 0.0),\n",
       " (3, 0.0),\n",
       " (2, 0.0),\n",
       " (1, 0.0),\n",
       " (0, 0.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_to_movie_rating[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90e44031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folder, \"user_to_movie_rating.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(user_to_movie_rating, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"D:\\GoodreadsData\\user_to_movie.pkl\", \"rb\") as f:\n",
    "#     user_to_movie = pickle.load(f)\n",
    "\n",
    "# with open(r\"D:\\GoodreadsData\\user_to_ratings.pkl\", \"rb\") as f:\n",
    "#     user_to_ratings = pickle.load(f)\n",
    "\n",
    "# with open(r\"D:\\GoodreadsData\\movie_to_user.pkl\", \"rb\") as f:\n",
    "#     movie_to_user = pickle.load(f)\n",
    "\n",
    "# with open(r\"D:\\GoodreadsData\\user_to_movie_rating.pkl\", \"rb\") as f:\n",
    "#     user_to_movie_rating = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40015694",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = {}\n",
    "for user, movie_ratings in user_to_movie_rating.items():\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for movie, rating in movie_ratings:\n",
    "        total += rating\n",
    "        count += 1\n",
    "    user_mean[user] = total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80141ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1421911421911424"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c57227b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_mean = data.groupby('movie_id')['rating'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "127e5344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029017857142857144"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04dbfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save user_mean\n",
    "with open(\"user_mean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_mean, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save movie_mean\n",
    "with open(\"movie_mean.pkl\", \"wb\") as f:\n",
    "    pickle.dump(movie_mean, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099aa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"user_mean.pkl\", \"rb\") as f:\n",
    "#     user_mean = pickle.load(f)\n",
    "\n",
    "# with open(\"movie_mean.pkl\", \"rb\") as f:\n",
    "#     movie_mean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00705b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_cosine_similarity(movie_i, movie_j, min_common=5):\n",
    "    users_i = set(movie_to_user[movie_i])\n",
    "    users_j = set(movie_to_user[movie_j])\n",
    "    common_users = users_i.intersection(users_j)\n",
    "\n",
    "    if len(common_users) < min_common:\n",
    "        return 0\n",
    "\n",
    "    numerator = 0\n",
    "    denominator_i = 0\n",
    "    denominator_j = 0\n",
    "\n",
    "    for user in common_users:\n",
    "        rating_i = user_movie_to_rating[(user, movie_i)]\n",
    "        rating_j = user_movie_to_rating[(user, movie_j)]\n",
    "        diff_i = rating_i - user_mean[user]\n",
    "        diff_j = rating_j - user_mean[user]\n",
    "\n",
    "        numerator += diff_i * diff_j\n",
    "        denominator_i += diff_i ** 2\n",
    "        denominator_j += diff_j ** 2\n",
    "\n",
    "    return numerator / (math.sqrt(denominator_i) * math.sqrt(denominator_j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "778e9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(min_common=5):\n",
    "    # 1. Precompute co-rated pairs (scales well)\n",
    "    co_rated = defaultdict(set)\n",
    "\n",
    "    for user, movies in user_to_movie.items():\n",
    "        for i in range(len(movies)):\n",
    "            for j in range(i+1, len(movies)):\n",
    "                a, b = movies[i], movies[j]\n",
    "                co_rated[a].add(b)\n",
    "                co_rated[b].add(a)\n",
    "\n",
    "    # 2. Compute similarity only for those pairs\n",
    "    movies = list(movie_to_user.keys())\n",
    "    similarity_matrix = {}\n",
    "\n",
    "    for idx, movie_i in enumerate(movies):\n",
    "        similarity_matrix[movie_i] = {}\n",
    "\n",
    "        for movie_j in co_rated[movie_i]:\n",
    "            sim = adjusted_cosine_similarity(movie_i, movie_j, min_common)\n",
    "            similarity_matrix[movie_i][movie_j] = sim\n",
    "\n",
    "        # Save incrementally to avoid memory blowup\n",
    "        with open(f'sim_{movie_i}.pkl', 'wb') as f:\n",
    "            pickle.dump(similarity_matrix[movie_i], f)\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            print(f\"{idx} movies processed...\")\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6106f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "folder = r\"D:\\GoodreadsData\"\n",
    "\n",
    "similarity_matrix = {}\n",
    "\n",
    "for movie in movie_to_user.keys():\n",
    "    filepath = os.path.join(folder, f\"sim_{movie}.pkl\")\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            similarity_matrix[movie] = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        similarity_matrix[movie] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "043a4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {},\n",
       " 1: {},\n",
       " 2: {},\n",
       " 3: {},\n",
       " 5: {},\n",
       " 6: {},\n",
       " 7: {},\n",
       " 8: {},\n",
       " 9: {},\n",
       " 10: {},\n",
       " 11: {},\n",
       " 12: {},\n",
       " 13: {},\n",
       " 14: {},\n",
       " 15: {},\n",
       " 16: {},\n",
       " 17: {},\n",
       " 18: {},\n",
       " 19: {},\n",
       " 20: {},\n",
       " 21: {},\n",
       " 22: {},\n",
       " 23: {},\n",
       " 25: {},\n",
       " 26: {},\n",
       " 27: {},\n",
       " 28: {},\n",
       " 29: {},\n",
       " 30: {},\n",
       " 31: {},\n",
       " 32: {},\n",
       " 33: {},\n",
       " 34: {},\n",
       " 35: {},\n",
       " 36: {},\n",
       " 37: {},\n",
       " 38: {},\n",
       " 39: {},\n",
       " 40: {},\n",
       " 41: {},\n",
       " 42: {},\n",
       " 43: {},\n",
       " 44: {},\n",
       " 46: {},\n",
       " 47: {},\n",
       " 48: {},\n",
       " 49: {},\n",
       " 50: {},\n",
       " 51: {},\n",
       " 52: {},\n",
       " 53: {},\n",
       " 55: {},\n",
       " 56: {},\n",
       " 57: {},\n",
       " 58: {},\n",
       " 59: {},\n",
       " 60: {},\n",
       " 61: {},\n",
       " 62: {},\n",
       " 63: {},\n",
       " 64: {},\n",
       " 65: {},\n",
       " 66: {},\n",
       " 67: {},\n",
       " 68: {},\n",
       " 69: {},\n",
       " 70: {},\n",
       " 71: {},\n",
       " 72: {},\n",
       " 74: {},\n",
       " 75: {},\n",
       " 76: {},\n",
       " 77: {},\n",
       " 78: {},\n",
       " 79: {},\n",
       " 80: {},\n",
       " 81: {},\n",
       " 82: {},\n",
       " 83: {},\n",
       " 84: {},\n",
       " 85: {},\n",
       " 86: {},\n",
       " 87: {},\n",
       " 88: {},\n",
       " 89: {},\n",
       " 90: {},\n",
       " 92: {},\n",
       " 93: {},\n",
       " 95: {},\n",
       " 96: {},\n",
       " 97: {},\n",
       " 98: {},\n",
       " 99: {},\n",
       " 100: {},\n",
       " 101: {},\n",
       " 103: {},\n",
       " 104: {},\n",
       " 105: {},\n",
       " 106: {},\n",
       " 108: {},\n",
       " 109: {},\n",
       " 110: {},\n",
       " 111: {},\n",
       " 112: {},\n",
       " 113: {},\n",
       " 115: {},\n",
       " 116: {},\n",
       " 117: {},\n",
       " 118: {},\n",
       " 119: {},\n",
       " 120: {},\n",
       " 121: {},\n",
       " 122: {},\n",
       " 123: {},\n",
       " 124: {},\n",
       " 125: {},\n",
       " 126: {},\n",
       " 127: {},\n",
       " 128: {},\n",
       " 129: {},\n",
       " 130: {},\n",
       " 131: {},\n",
       " 132: {},\n",
       " 133: {},\n",
       " 134: {},\n",
       " 135: {},\n",
       " 136: {},\n",
       " 137: {},\n",
       " 138: {},\n",
       " 139: {},\n",
       " 140: {},\n",
       " 141: {},\n",
       " 142: {},\n",
       " 143: {},\n",
       " 144: {},\n",
       " 145: {},\n",
       " 148: {},\n",
       " 149: {},\n",
       " 150: {},\n",
       " 151: {},\n",
       " 152: {},\n",
       " 153: {},\n",
       " 154: {},\n",
       " 155: {},\n",
       " 156: {},\n",
       " 157: {},\n",
       " 158: {},\n",
       " 159: {},\n",
       " 160: {},\n",
       " 161: {},\n",
       " 162: {},\n",
       " 163: {},\n",
       " 164: {},\n",
       " 165: {},\n",
       " 166: {},\n",
       " 168: {},\n",
       " 170: {},\n",
       " 171: {},\n",
       " 172: {},\n",
       " 174: {},\n",
       " 175: {},\n",
       " 176: {},\n",
       " 177: {},\n",
       " 178: {},\n",
       " 179: {},\n",
       " 180: {},\n",
       " 181: {},\n",
       " 182: {},\n",
       " 183: {},\n",
       " 184: {},\n",
       " 185: {},\n",
       " 186: {},\n",
       " 188: {},\n",
       " 189: {},\n",
       " 190: {},\n",
       " 191: {},\n",
       " 192: {},\n",
       " 194: {},\n",
       " 195: {},\n",
       " 197: {},\n",
       " 198: {},\n",
       " 199: {},\n",
       " 200: {},\n",
       " 201: {},\n",
       " 202: {},\n",
       " 203: {},\n",
       " 204: {},\n",
       " 205: {},\n",
       " 206: {},\n",
       " 207: {},\n",
       " 208: {},\n",
       " 209: {},\n",
       " 210: {},\n",
       " 211: {},\n",
       " 212: {},\n",
       " 213: {},\n",
       " 214: {},\n",
       " 215: {},\n",
       " 216: {},\n",
       " 217: {},\n",
       " 218: {},\n",
       " 220: {},\n",
       " 221: {},\n",
       " 222: {},\n",
       " 223: {},\n",
       " 224: {},\n",
       " 225: {},\n",
       " 226: {},\n",
       " 227: {},\n",
       " 228: {},\n",
       " 229: {},\n",
       " 230: {},\n",
       " 231: {},\n",
       " 232: {},\n",
       " 233: {},\n",
       " 234: {},\n",
       " 235: {},\n",
       " 236: {},\n",
       " 237: {},\n",
       " 238: {},\n",
       " 239: {},\n",
       " 241: {},\n",
       " 242: {},\n",
       " 243: {},\n",
       " 244: {},\n",
       " 245: {},\n",
       " 246: {},\n",
       " 247: {},\n",
       " 248: {},\n",
       " 250: {},\n",
       " 251: {},\n",
       " 252: {},\n",
       " 253: {},\n",
       " 254: {},\n",
       " 255: {},\n",
       " 256: {},\n",
       " 257: {},\n",
       " 258: {},\n",
       " 259: {},\n",
       " 260: {},\n",
       " 261: {},\n",
       " 262: {},\n",
       " 263: {},\n",
       " 264: {},\n",
       " 265: {},\n",
       " 266: {},\n",
       " 267: {},\n",
       " 269: {},\n",
       " 270: {},\n",
       " 271: {},\n",
       " 272: {},\n",
       " 273: {},\n",
       " 274: {},\n",
       " 275: {},\n",
       " 276: {},\n",
       " 277: {},\n",
       " 278: {},\n",
       " 279: {},\n",
       " 281: {},\n",
       " 283: {},\n",
       " 284: {},\n",
       " 285: {},\n",
       " 286: {},\n",
       " 287: {},\n",
       " 288: {},\n",
       " 289: {},\n",
       " 290: {},\n",
       " 291: {},\n",
       " 292: {},\n",
       " 293: {},\n",
       " 294: {},\n",
       " 295: {},\n",
       " 296: {},\n",
       " 297: {},\n",
       " 298: {},\n",
       " 299: {},\n",
       " 300: {},\n",
       " 301: {},\n",
       " 302: {},\n",
       " 303: {},\n",
       " 304: {},\n",
       " 305: {},\n",
       " 306: {},\n",
       " 307: {},\n",
       " 308: {},\n",
       " 309: {},\n",
       " 310: {},\n",
       " 311: {},\n",
       " 313: {},\n",
       " 314: {},\n",
       " 315: {},\n",
       " 316: {},\n",
       " 317: {},\n",
       " 318: {},\n",
       " 319: {},\n",
       " 320: {},\n",
       " 321: {},\n",
       " 322: {},\n",
       " 323: {},\n",
       " 324: {},\n",
       " 325: {},\n",
       " 327: {},\n",
       " 328: {},\n",
       " 329: {},\n",
       " 331: {},\n",
       " 332: {},\n",
       " 334: {},\n",
       " 335: {},\n",
       " 336: {},\n",
       " 337: {},\n",
       " 338: {},\n",
       " 340: {},\n",
       " 341: {},\n",
       " 342: {},\n",
       " 343: {},\n",
       " 344: {},\n",
       " 345: {},\n",
       " 346: {},\n",
       " 347: {},\n",
       " 348: {},\n",
       " 349: {},\n",
       " 350: {},\n",
       " 351: {},\n",
       " 352: {},\n",
       " 353: {},\n",
       " 354: {},\n",
       " 355: {},\n",
       " 356: {},\n",
       " 357: {},\n",
       " 358: {},\n",
       " 359: {},\n",
       " 360: {},\n",
       " 361: {},\n",
       " 365: {},\n",
       " 367: {},\n",
       " 368: {},\n",
       " 369: {},\n",
       " 370: {},\n",
       " 371: {},\n",
       " 372: {},\n",
       " 373: {},\n",
       " 374: {},\n",
       " 375: {},\n",
       " 376: {},\n",
       " 377: {},\n",
       " 378: {},\n",
       " 379: {},\n",
       " 380: {},\n",
       " 381: {},\n",
       " 382: {},\n",
       " 383: {},\n",
       " 384: {},\n",
       " 385: {},\n",
       " 387: {},\n",
       " 388: {},\n",
       " 389: {},\n",
       " 390: {},\n",
       " 391: {},\n",
       " 392: {},\n",
       " 393: {},\n",
       " 394: {},\n",
       " 397: {},\n",
       " 398: {},\n",
       " 399: {},\n",
       " 400: {},\n",
       " 401: {},\n",
       " 402: {},\n",
       " 403: {},\n",
       " 404: {},\n",
       " 405: {},\n",
       " 406: {},\n",
       " 407: {},\n",
       " 408: {},\n",
       " 409: {},\n",
       " 410: {},\n",
       " 411: {},\n",
       " 412: {},\n",
       " 413: {},\n",
       " 414: {},\n",
       " 415: {},\n",
       " 416: {},\n",
       " 417: {},\n",
       " 418: {},\n",
       " 419: {},\n",
       " 420: {},\n",
       " 421: {},\n",
       " 422: {},\n",
       " 423: {},\n",
       " 424: {},\n",
       " 425: {},\n",
       " 427: {},\n",
       " 428: {},\n",
       " 429: {},\n",
       " 430: {},\n",
       " 431: {},\n",
       " 432: {},\n",
       " 433: {},\n",
       " 434: {},\n",
       " 436: {},\n",
       " 437: {},\n",
       " 438: {},\n",
       " 439: {},\n",
       " 440: {},\n",
       " 441: {},\n",
       " 442: {},\n",
       " 443: {},\n",
       " 444: {},\n",
       " 445: {},\n",
       " 446: {},\n",
       " 447: {},\n",
       " 448: {},\n",
       " 449: {},\n",
       " 450: {},\n",
       " 451: {},\n",
       " 452: {},\n",
       " 453: {},\n",
       " 454: {},\n",
       " 455: {},\n",
       " 456: {},\n",
       " 457: {},\n",
       " 458: {},\n",
       " 459: {},\n",
       " 460: {},\n",
       " 461: {},\n",
       " 462: {},\n",
       " 463: {},\n",
       " 464: {},\n",
       " 466: {},\n",
       " 467: {},\n",
       " 468: {},\n",
       " 469: {},\n",
       " 470: {},\n",
       " 471: {},\n",
       " 472: {},\n",
       " 473: {},\n",
       " 474: {},\n",
       " 475: {},\n",
       " 476: {},\n",
       " 477: {},\n",
       " 478: {},\n",
       " 479: {},\n",
       " 480: {},\n",
       " 481: {},\n",
       " 482: {},\n",
       " 483: {},\n",
       " 484: {},\n",
       " 485: {},\n",
       " 486: {},\n",
       " 488: {},\n",
       " 489: {},\n",
       " 490: {},\n",
       " 491: {},\n",
       " 492: {},\n",
       " 493: {},\n",
       " 494: {},\n",
       " 495: {},\n",
       " 496: {},\n",
       " 497: {},\n",
       " 498: {},\n",
       " 499: {},\n",
       " 500: {},\n",
       " 501: {},\n",
       " 502: {},\n",
       " 503: {},\n",
       " 504: {},\n",
       " 506: {},\n",
       " 507: {},\n",
       " 509: {},\n",
       " 510: {},\n",
       " 511: {},\n",
       " 512: {},\n",
       " 514: {},\n",
       " 515: {},\n",
       " 516: {},\n",
       " 517: {},\n",
       " 520: {},\n",
       " 521: {},\n",
       " 522: {},\n",
       " 523: {},\n",
       " 524: {},\n",
       " 525: {},\n",
       " 526: {},\n",
       " 527: {},\n",
       " 528: {},\n",
       " 529: {},\n",
       " 530: {},\n",
       " 531: {},\n",
       " 532: {},\n",
       " 533: {},\n",
       " 534: {},\n",
       " 535: {},\n",
       " 536: {},\n",
       " 537: {},\n",
       " 538: {},\n",
       " 539: {},\n",
       " 540: {},\n",
       " 541: {},\n",
       " 542: {},\n",
       " 543: {},\n",
       " 544: {},\n",
       " 545: {},\n",
       " 546: {},\n",
       " 547: {},\n",
       " 548: {},\n",
       " 550: {},\n",
       " 551: {},\n",
       " 552: {},\n",
       " 553: {},\n",
       " 554: {},\n",
       " 555: {},\n",
       " 556: {},\n",
       " 557: {},\n",
       " 558: {},\n",
       " 559: {},\n",
       " 560: {},\n",
       " 561: {},\n",
       " 562: {},\n",
       " 563: {},\n",
       " 564: {},\n",
       " 565: {},\n",
       " 566: {},\n",
       " 567: {},\n",
       " 568: {},\n",
       " 569: {},\n",
       " 570: {},\n",
       " 572: {},\n",
       " 573: {},\n",
       " 574: {},\n",
       " 575: {},\n",
       " 576: {},\n",
       " 577: {},\n",
       " 578: {},\n",
       " 579: {},\n",
       " 580: {},\n",
       " 581: {},\n",
       " 582: {},\n",
       " 583: {},\n",
       " 584: {},\n",
       " 586: {},\n",
       " 587: {},\n",
       " 588: {},\n",
       " 590: {},\n",
       " 591: {},\n",
       " 592: {},\n",
       " 594: {},\n",
       " 596: {},\n",
       " 597: {},\n",
       " 598: {},\n",
       " 599: {},\n",
       " 600: {},\n",
       " 601: {},\n",
       " 602: {},\n",
       " 603: {},\n",
       " 605: {},\n",
       " 607: {},\n",
       " 608: {},\n",
       " 609: {},\n",
       " 610: {},\n",
       " 611: {},\n",
       " 612: {},\n",
       " 613: {},\n",
       " 614: {},\n",
       " 615: {},\n",
       " 616: {},\n",
       " 617: {},\n",
       " 618: {},\n",
       " 619: {},\n",
       " 620: {},\n",
       " 621: {},\n",
       " 622: {},\n",
       " 623: {},\n",
       " 624: {},\n",
       " 625: {},\n",
       " 626: {},\n",
       " 627: {},\n",
       " 628: {},\n",
       " 629: {},\n",
       " 630: {},\n",
       " 631: {},\n",
       " 632: {},\n",
       " 633: {},\n",
       " 634: {},\n",
       " 635: {},\n",
       " 636: {},\n",
       " 637: {},\n",
       " 638: {},\n",
       " 639: {},\n",
       " 640: {},\n",
       " 642: {},\n",
       " 643: {},\n",
       " 644: {},\n",
       " 646: {},\n",
       " 647: {},\n",
       " 648: {},\n",
       " 649: {},\n",
       " 650: {},\n",
       " 651: {},\n",
       " 652: {},\n",
       " 653: {},\n",
       " 654: {},\n",
       " 655: {},\n",
       " 656: {},\n",
       " 657: {},\n",
       " 658: {},\n",
       " 659: {},\n",
       " 660: {},\n",
       " 661: {},\n",
       " 662: {},\n",
       " 663: {},\n",
       " 664: {},\n",
       " 665: {},\n",
       " 666: {},\n",
       " 667: {},\n",
       " 668: {},\n",
       " 669: {},\n",
       " 670: {},\n",
       " 671: {},\n",
       " 673: {},\n",
       " 675: {},\n",
       " 676: {},\n",
       " 677: {},\n",
       " 678: {},\n",
       " 679: {},\n",
       " 680: {},\n",
       " 681: {},\n",
       " 682: {},\n",
       " 683: {},\n",
       " 684: {},\n",
       " 685: {},\n",
       " 688: {},\n",
       " 689: {},\n",
       " 690: {},\n",
       " 691: {},\n",
       " 692: {},\n",
       " 693: {},\n",
       " 695: {},\n",
       " 696: {},\n",
       " 697: {},\n",
       " 698: {},\n",
       " 699: {},\n",
       " 700: {},\n",
       " 701: {},\n",
       " 702: {},\n",
       " 703: {},\n",
       " 704: {},\n",
       " 706: {},\n",
       " 707: {},\n",
       " 708: {},\n",
       " 710: {},\n",
       " 711: {},\n",
       " 712: {},\n",
       " 713: {},\n",
       " 714: {},\n",
       " 715: {},\n",
       " 716: {},\n",
       " 717: {},\n",
       " 718: {},\n",
       " 719: {},\n",
       " 720: {},\n",
       " 721: {},\n",
       " 722: {},\n",
       " 723: {},\n",
       " 724: {},\n",
       " 731: {},\n",
       " 732: {},\n",
       " 733: {},\n",
       " 734: {},\n",
       " 736: {},\n",
       " 737: {},\n",
       " 738: {},\n",
       " 739: {},\n",
       " 740: {},\n",
       " 741: {},\n",
       " 742: {},\n",
       " 743: {},\n",
       " 744: {},\n",
       " 745: {},\n",
       " 746: {},\n",
       " 747: {},\n",
       " 748: {},\n",
       " 749: {},\n",
       " 750: {},\n",
       " 753: {},\n",
       " 754: {},\n",
       " 756: {},\n",
       " 757: {},\n",
       " 758: {},\n",
       " 759: {},\n",
       " 760: {},\n",
       " 761: {},\n",
       " 762: {},\n",
       " 763: {},\n",
       " 764: {},\n",
       " 765: {},\n",
       " 766: {},\n",
       " 767: {},\n",
       " 768: {},\n",
       " 769: {},\n",
       " 770: {},\n",
       " 771: {},\n",
       " 772: {},\n",
       " 773: {},\n",
       " 774: {},\n",
       " 776: {},\n",
       " 779: {},\n",
       " 780: {},\n",
       " 781: {},\n",
       " 783: {},\n",
       " 784: {},\n",
       " 785: {},\n",
       " 786: {},\n",
       " 787: {},\n",
       " 788: {},\n",
       " 789: {},\n",
       " 790: {},\n",
       " 791: {},\n",
       " 792: {},\n",
       " 795: {},\n",
       " 796: {},\n",
       " 797: {},\n",
       " 798: {},\n",
       " 799: {},\n",
       " 801: {},\n",
       " 802: {},\n",
       " 803: {},\n",
       " 804: {},\n",
       " 805: {},\n",
       " 807: {},\n",
       " 808: {},\n",
       " 809: {},\n",
       " 810: {},\n",
       " 811: {},\n",
       " 812: {},\n",
       " 815: {},\n",
       " 816: {},\n",
       " 817: {},\n",
       " 818: {},\n",
       " 819: {},\n",
       " 820: {},\n",
       " 821: {},\n",
       " 822: {},\n",
       " 823: {},\n",
       " 824: {},\n",
       " 825: {},\n",
       " 826: {},\n",
       " 827: {},\n",
       " 828: {},\n",
       " 829: {},\n",
       " 830: {},\n",
       " 831: {},\n",
       " 832: {},\n",
       " 833: {},\n",
       " 834: {},\n",
       " 835: {},\n",
       " 837: {},\n",
       " 838: {},\n",
       " 839: {},\n",
       " 842: {},\n",
       " 843: {},\n",
       " 844: {},\n",
       " 845: {},\n",
       " 846: {},\n",
       " 847: {},\n",
       " 848: {},\n",
       " 849: {},\n",
       " 850: {},\n",
       " 851: {},\n",
       " 852: {},\n",
       " 853: {},\n",
       " 854: {},\n",
       " 855: {},\n",
       " 856: {},\n",
       " 857: {},\n",
       " 858: {},\n",
       " 859: {},\n",
       " 860: {},\n",
       " 861: {},\n",
       " 862: {},\n",
       " 863: {},\n",
       " 864: {},\n",
       " 865: {},\n",
       " 866: {},\n",
       " 867: {},\n",
       " 868: {},\n",
       " 869: {},\n",
       " 870: {},\n",
       " 871: {},\n",
       " 872: {},\n",
       " 873: {},\n",
       " 874: {},\n",
       " 875: {},\n",
       " 876: {},\n",
       " 877: {},\n",
       " 878: {},\n",
       " 879: {},\n",
       " 880: {},\n",
       " 881: {},\n",
       " 882: {},\n",
       " 883: {},\n",
       " 884: {},\n",
       " 885: {},\n",
       " 886: {},\n",
       " 887: {},\n",
       " 888: {},\n",
       " 889: {},\n",
       " 890: {},\n",
       " 891: {},\n",
       " 892: {},\n",
       " 893: {},\n",
       " 895: {},\n",
       " 896: {},\n",
       " 897: {},\n",
       " 898: {},\n",
       " 899: {},\n",
       " 900: {},\n",
       " 901: {},\n",
       " 903: {},\n",
       " 904: {},\n",
       " 905: {},\n",
       " 906: {},\n",
       " 907: {},\n",
       " 908: {},\n",
       " 909: {},\n",
       " 910: {},\n",
       " 912: {},\n",
       " 914: {},\n",
       " 915: {},\n",
       " 916: {},\n",
       " 917: {},\n",
       " 918: {},\n",
       " 919: {},\n",
       " 920: {},\n",
       " 921: {},\n",
       " 922: {},\n",
       " 923: {},\n",
       " 924: {},\n",
       " 927: {},\n",
       " 928: {},\n",
       " 929: {},\n",
       " 930: {},\n",
       " 931: {},\n",
       " 932: {},\n",
       " 933: {},\n",
       " 934: {},\n",
       " 935: {},\n",
       " 936: {},\n",
       " 937: {},\n",
       " 938: {},\n",
       " 939: {},\n",
       " 940: {},\n",
       " 941: {},\n",
       " 942: {},\n",
       " 943: {},\n",
       " 944: {},\n",
       " 945: {},\n",
       " 946: {},\n",
       " 947: {},\n",
       " 948: {},\n",
       " 949: {},\n",
       " 950: {},\n",
       " 951: {},\n",
       " 953: {},\n",
       " 954: {},\n",
       " 955: {},\n",
       " 956: {},\n",
       " 957: {},\n",
       " 958: {},\n",
       " 959: {},\n",
       " 960: {},\n",
       " 961: {},\n",
       " 962: {},\n",
       " 963: {},\n",
       " 964: {},\n",
       " 965: {},\n",
       " 966: {},\n",
       " 967: {},\n",
       " 968: {},\n",
       " 972: {},\n",
       " 973: {},\n",
       " 975: {},\n",
       " 976: {},\n",
       " 977: {},\n",
       " 978: {},\n",
       " 979: {},\n",
       " 980: {},\n",
       " 981: {},\n",
       " 982: {},\n",
       " 984: {},\n",
       " 985: {},\n",
       " 986: {},\n",
       " 988: {},\n",
       " 990: {},\n",
       " 991: {},\n",
       " 992: {},\n",
       " 993: {},\n",
       " 994: {},\n",
       " 995: {},\n",
       " 996: {},\n",
       " 997: {},\n",
       " 998: {},\n",
       " 999: {},\n",
       " 1000: {},\n",
       " 1001: {},\n",
       " 1002: {},\n",
       " 1003: {},\n",
       " 1004: {},\n",
       " 1005: {},\n",
       " 1006: {},\n",
       " 1007: {},\n",
       " 1008: {},\n",
       " 1009: {},\n",
       " 1010: {},\n",
       " 1011: {},\n",
       " 1012: {},\n",
       " 1013: {},\n",
       " 1014: {},\n",
       " 1015: {},\n",
       " 1016: {},\n",
       " 1017: {},\n",
       " 1018: {},\n",
       " 1019: {},\n",
       " 1020: {},\n",
       " 1021: {},\n",
       " 1022: {},\n",
       " 1023: {},\n",
       " 1024: {},\n",
       " 1025: {},\n",
       " 1026: {},\n",
       " 1027: {},\n",
       " 1028: {},\n",
       " 1029: {},\n",
       " 1030: {},\n",
       " 1031: {},\n",
       " 1032: {},\n",
       " 1033: {},\n",
       " 1034: {},\n",
       " 1035: {},\n",
       " 1036: {},\n",
       " 1037: {},\n",
       " 1038: {},\n",
       " 1039: {},\n",
       " 1040: {},\n",
       " 1041: {},\n",
       " 1042: {},\n",
       " 1043: {},\n",
       " 1044: {},\n",
       " 1045: {},\n",
       " 1046: {},\n",
       " 1047: {},\n",
       " 1048: {},\n",
       " 1049: {},\n",
       " 1050: {},\n",
       " 1051: {},\n",
       " 1052: {},\n",
       " 1053: {},\n",
       " 1054: {},\n",
       " 1055: {},\n",
       " 1056: {},\n",
       " 1057: {},\n",
       " 1058: {},\n",
       " 1059: {},\n",
       " 1060: {},\n",
       " 1061: {},\n",
       " 1062: {},\n",
       " 1063: {},\n",
       " 1064: {},\n",
       " 1065: {},\n",
       " 1066: {},\n",
       " 1067: {},\n",
       " 1068: {},\n",
       " 1069: {},\n",
       " 1070: {},\n",
       " 1071: {},\n",
       " 1072: {},\n",
       " 1073: {},\n",
       " 1074: {},\n",
       " 1075: {},\n",
       " 1076: {},\n",
       " 1077: {},\n",
       " 1078: {},\n",
       " 1079: {},\n",
       " 1080: {},\n",
       " 1081: {},\n",
       " 1083: {},\n",
       " 1084: {},\n",
       " 1085: {},\n",
       " 1086: {},\n",
       " 1087: {},\n",
       " 1088: {},\n",
       " 1089: {},\n",
       " 1090: {},\n",
       " 1091: {},\n",
       " 1092: {},\n",
       " 1093: {},\n",
       " 1094: {},\n",
       " 1095: {},\n",
       " 1096: {},\n",
       " 1097: {},\n",
       " 1098: {},\n",
       " 1099: {},\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59c3e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user, target_movie, k=25):\n",
    "    rated_movies = user_to_movie[user]\n",
    "    similarities = []\n",
    "\n",
    "    for movie in rated_movies:\n",
    "        if (target_movie in similarity_matrix) and (movie in similarity_matrix[target_movie]):\n",
    "            similarity = similarity_matrix[target_movie][movie]\n",
    "        elif (movie in similarity_matrix) and (target_movie in similarity_matrix[movie]):\n",
    "            similarity = similarity_matrix[movie][target_movie]\n",
    "        else:\n",
    "            similarity = 0\n",
    "\n",
    "        similarities.append((movie, similarity))\n",
    "\n",
    "    similarities.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    neighbors = similarities[:k]\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for movie, sim in neighbors:\n",
    "        rating = user_movie_to_rating[(user, movie)]\n",
    "        base = movie_mean[movie]\n",
    "        numerator += sim * (rating - base)\n",
    "        denominator += abs(sim)\n",
    "\n",
    "    return movie_mean[target_movie] + numerator / (denominator + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2eedd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 movies processed...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_movie_to_rating' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m movies processed...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m predictions[movie] \u001b[38;5;241m=\u001b[39m predict_rating(target_user, movie)\n",
      "Cell \u001b[1;32mIn[46], line 21\u001b[0m, in \u001b[0;36mpredict_rating\u001b[1;34m(user, target_movie, k)\u001b[0m\n\u001b[0;32m     19\u001b[0m denominator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m movie, sim \u001b[38;5;129;01min\u001b[39;00m neighbors:\n\u001b[1;32m---> 21\u001b[0m     rating \u001b[38;5;241m=\u001b[39m user_movie_to_rating[(user, movie)]\n\u001b[0;32m     22\u001b[0m     base \u001b[38;5;241m=\u001b[39m movie_mean[movie]\n\u001b[0;32m     23\u001b[0m     numerator \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sim \u001b[38;5;241m*\u001b[39m (rating \u001b[38;5;241m-\u001b[39m base)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_movie_to_rating' is not defined"
     ]
    }
   ],
   "source": [
    "target_user = 948   # example from your CSV\n",
    "\n",
    "all_movies = set(movie_to_user.keys())\n",
    "rated_movies = set(user_to_movie[target_user])\n",
    "candidate_movies = all_movies - rated_movies\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for idx, movie in enumerate(candidate_movies):\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"{idx} movies processed...\")\n",
    "\n",
    "    predictions[movie] = predict_rating(target_user, movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "print(\"\\nTop 5 Recommendations:\")\n",
    "for movie, pred in top_5:\n",
    "    print(f\"Book {movie}, Predicted Rating: {round(pred, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
